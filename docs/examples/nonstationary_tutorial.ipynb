{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copyright 2023-2023 Lawrence Livermore National Security, LLC and other MuyGPyS\n",
    "Project Developers. See the top-level COPYRIGHT file for details.\n",
    "\n",
    "SPDX-License-Identifier: MIT"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Nonstationary tutorial\n",
    "\n",
    "This notebook demonstrates how to use hierarchical nonstationary hyperparameters to perform nonstationary regression using a hierarchical model.\n",
    "\n",
    "⚠️ _Note that this is still an experimental feature at this point._ ⚠️"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will set a random seed here for consistency when building docs.\n",
    "In practice we would not fix a seed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.random.seed(0)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preliminary setup"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For simplicity, we start with an isotropic distortion so we only need to use a single `HierarchicalNonstationaryHyperparameter`. Let's also build a GP with a fixed length scale for comparison."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from MuyGPyS.gp import MuyGPS\n",
    "from MuyGPyS.gp.distortion import IsotropicDistortion, l2\n",
    "from MuyGPyS.gp.hyperparameter import ScalarHyperparameter\n",
    "from MuyGPyS.gp.hyperparameter.experimental import (\n",
    "    sample_knots,\n",
    "    HierarchicalNonstationaryHyperparameter,\n",
    ")\n",
    "from MuyGPyS.gp.kernels import RBF\n",
    "\n",
    "muygps_fixed = MuyGPS(\n",
    "    kernel=RBF(\n",
    "        metric=IsotropicDistortion(\n",
    "            l2,\n",
    "            length_scale=ScalarHyperparameter(1.0),\n",
    "        ),\n",
    "    ),\n",
    ")\n",
    "\n",
    "knot_count = 6\n",
    "knot_features = sample_knots(feature_count=1, knot_count=knot_count)\n",
    "knot_values = np.random.uniform(size=knot_count)\n",
    "high_level_kernel = RBF()\n",
    "\n",
    "muygps = MuyGPS(\n",
    "    kernel=RBF(\n",
    "        metric=IsotropicDistortion(\n",
    "            l2,\n",
    "            length_scale=HierarchicalNonstationaryHyperparameter(\n",
    "                knot_features, knot_values, high_level_kernel\n",
    "            ),\n",
    "        ),\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's create some training data with a little bit of noise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.linspace(-5, 5, num=50)\n",
    "y = np.sinc(x) - np.mean(np.sinc(x))\n",
    "train_features = np.reshape(x + np.random.normal(scale=0.02, size=50), (-1, 1))\n",
    "train_responses = np.reshape(y + np.random.normal(scale=0.02, size=50), (-1, 1))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can visualize what that looks like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(x, y)\n",
    "plt.plot(train_features, train_responses, '.')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're going to try to predict random points of that function so let's create test features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_features = np.sort(\n",
    "    np.concatenate(([-5, 5], np.random.uniform(-5, 5, size=18)))\n",
    ").reshape((-1, 1))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can proceed as usual to generate the nearest neighbors lookup index and tensors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from MuyGPyS.neighbors import NN_Wrapper\n",
    "\n",
    "nn_count = 30\n",
    "nbrs_lookup = NN_Wrapper(train_features, nn_count, nn_method=\"exact\", algorithm=\"ball_tree\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that in this simple example we're using all of the data as batch points, i.e. we're not really batching, since the dataset is very small."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from MuyGPyS.gp.tensors import make_predict_tensors\n",
    "\n",
    "test_count, _ = test_features.shape\n",
    "indices = np.arange(test_count)\n",
    "test_nn_indices, _ = nbrs_lookup.get_nns(test_features)\n",
    "\n",
    "(\n",
    "    test_crosswise_diffs,\n",
    "    test_pairwise_diffs,\n",
    "    test_nn_targets,\n",
    ") = make_predict_tensors(\n",
    "    indices,\n",
    "    test_nn_indices,\n",
    "    test_features,\n",
    "    train_features,\n",
    "    train_responses,\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normally, at this point, we would optimize hyperparameters, but that part hasn't been implemented yet so we'll skip it for now."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One notable difference when using a hierarchical model is that the kernel takes an additional tensor, the batch tensor, which can be easily obtained using the `batch_features_tensor` helper function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from MuyGPyS.gp.tensors import batch_features_tensor\n",
    "\n",
    "batch_features = batch_features_tensor(test_features, indices)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we're ready to realize the kernel tensors and use them to predict the response of the test data. First using the GP with a fixed length scale."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Kcross_fixed = muygps_fixed.kernel(test_crosswise_diffs, batch_features)\n",
    "K_fixed = muygps_fixed.kernel(test_pairwise_diffs, batch_features)\n",
    "test_responses_mean_fixed = muygps_fixed.posterior_mean(K_fixed, Kcross_fixed, test_nn_targets)\n",
    "test_responses_var_fixed = muygps_fixed.posterior_variance(K_fixed, Kcross_fixed)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then the hierarchical GP."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Kcross = muygps.kernel(test_crosswise_diffs, batch_features)\n",
    "K = muygps.kernel(test_pairwise_diffs, batch_features)\n",
    "test_responses_mean = muygps.posterior_mean(K, Kcross, test_nn_targets)\n",
    "test_responses_var = muygps.posterior_variance(K, Kcross)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And we can visualize the results by plotting the predicted means as well as one predicted standard deviation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(x, y, label=\"truth\")\n",
    "plt.plot(test_features, test_responses_mean_fixed, \".-\", label=\"fixed\")\n",
    "plt.plot(test_features, test_responses_mean, \".--\", label=\"hierarchical\")\n",
    "plt.fill_between(\n",
    "    np.ravel(test_features),\n",
    "    np.ravel(test_responses_mean_fixed + np.sqrt(test_responses_var_fixed) * 1.96),\n",
    "    np.ravel(test_responses_mean_fixed - np.sqrt(test_responses_var_fixed) * 1.96),\n",
    "    facecolor=\"C1\",\n",
    "    alpha=0.2,\n",
    ")\n",
    "plt.fill_between(\n",
    "    np.ravel(test_features),\n",
    "    np.ravel(test_responses_mean + np.sqrt(test_responses_var) * 1.96),\n",
    "    np.ravel(test_responses_mean - np.sqrt(test_responses_var) * 1.96),\n",
    "    facecolor=\"C2\",\n",
    "    alpha=0.2,\n",
    ")\n",
    "plt.legend()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
