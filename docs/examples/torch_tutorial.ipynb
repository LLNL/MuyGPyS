{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2c123e93",
   "metadata": {},
   "source": [
    "Copyright 2021-2023 Lawrence Livermore National Security, LLC and other MuyGPyS Project Developers. See the top-level COPYRIGHT file for details.\n",
    "\n",
    "SPDX-License-Identifier: MIT\n",
    "\n",
    "# Deep Kernels with MuyGPs in PyTorch Tutorial\n",
    "\n",
    "In this tutorial, we outline how to construct a simple deep kernel model using the PyTorch implementation of MuyGPs.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a02f1d56",
   "metadata": {},
   "outputs": [],
   "source": [
    "from MuyGPyS import config\n",
    "config.update(\"muygpys_backend\",\"torch\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f35729ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b83dc4cd",
   "metadata": {},
   "source": [
    "We use the MNIST classification problem as a benchmark. We will use the deep kernel MuyGPs model to classify images of handwritten digits between 0 and 9. We will use a fully-connected architecture, meaning we will have to vectorize each image prior to training. We download the training and testing data using the torchvision.datasets API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f71dd370",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision\n",
    "import os\n",
    "from torch.nn.functional import one_hot\n",
    "root = './data'\n",
    "if not os.path.exists(root):\n",
    "    os.mkdir(root)\n",
    "    \n",
    "# Download and transform MNIST dataset    \n",
    "    \n",
    "trans = torchvision.transforms.Compose([torchvision.transforms.ToTensor(), torchvision.transforms.Normalize((0.5,),(1.0,))])\n",
    "train_set = torchvision.datasets.MNIST(root=root,train=True,transform=trans,download=True)\n",
    "test_set = torchvision.datasets.MNIST(root=root,train=False,transform=trans,download=True)\n",
    "\n",
    "\n",
    "# Ten Different Digits, 60,000 training samples, 10,000 test samples, 784 features\n",
    "\n",
    "num_classes = 10\n",
    "num_train_samples = 60000\n",
    "num_test_samples = 10000\n",
    "num_features = 784\n",
    "\n",
    "\n",
    "# Construct training and test data feature tensors. Vectorize the images of digits and one-hot encode the classes.\n",
    "\n",
    "train_features = torch.zeros((num_train_samples,num_features))\n",
    "train_responses = torch.zeros((num_train_samples,num_classes))\n",
    "\n",
    "for i in range(num_train_samples):\n",
    "    train_features[i,:] = train_set[i][0].flatten()\n",
    "    train_responses[i,:] = one_hot(torch.tensor(train_set[i][1]).to(torch.int64),num_classes=num_classes)\n",
    "\n",
    "\n",
    "test_features = torch.zeros((num_test_samples,num_features))\n",
    "test_responses = torch.zeros((num_test_samples,num_classes))\n",
    "\n",
    "for i in range(num_test_samples):\n",
    "    test_features[i,:] = test_set[i][0].flatten()\n",
    "    test_responses[i,:] = one_hot(torch.tensor(test_set[i][1]).to(torch.int64),num_classes=num_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "319abcfa",
   "metadata": {},
   "source": [
    "We set up our nearest neighbor lookup structure using the NN_Wrapper data structure in MuyGPs. We then define our batch and construct tensor containing the features and targets of the batched elements and their nearest neighbors. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa31e88f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "import random\n",
    "from torch.optim.lr_scheduler import ExponentialLR\n",
    "torch.autograd.set_detect_anomaly(True)\n",
    "#Define the nearest neighbor data structure, setting the number of nearest neighbors and choosing the NN algorithm\n",
    "#For reproductibility we set a random seed\n",
    "np.random.seed(0)\n",
    "test_count, _ = test_features.shape\n",
    "train_count, _ = train_features.shape\n",
    "\n",
    "from MuyGPyS.neighbors import NN_Wrapper\n",
    "nn_count = 30\n",
    "nbrs_lookup = NN_Wrapper(train_features, nn_count, nn_method=\"hnsw\")\n",
    "\n",
    "#We will make use of batching in our hyperparameter training\n",
    "from MuyGPyS.optimize.batch import sample_batch\n",
    "batch_count = 500\n",
    "batch_indices, batch_nn_indices = sample_batch(\n",
    "    nbrs_lookup, batch_count, train_count\n",
    ")\n",
    "\n",
    "batch_indices, batch_nn_indices = batch_indices.astype(np.int64), batch_nn_indices.astype(np.int64)\n",
    "batch_indices, batch_nn_indices = torch.from_numpy(batch_indices), torch.from_numpy(batch_nn_indices)\n",
    "\n",
    "\n",
    "batch_features = train_features[batch_indices,:]\n",
    "batch_targets = train_responses[batch_indices, :]\n",
    "batch_nn_targets = train_responses[batch_nn_indices, :]\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    train_features = train_features.cuda()\n",
    "    train_responses = train_responses.cuda()\n",
    "    test_features = test_features.cuda()\n",
    "    test_responses = test_responses.cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67ef039a",
   "metadata": {},
   "source": [
    "We now construct a custom MuyGPs deep kernel class inheriting from PyTorch. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afa79b85",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Building and Training Neural Network')\n",
    "\n",
    "#Import MuyGPs_layer and MultivariateMuyGPs_layer objects for composing PyTorch models.\n",
    "from MuyGPyS.torch.muygps_layer import MuyGPs_layer, MultivariateMuyGPs_layer\n",
    "\n",
    "\n",
    "#Build a custom object inheriting from the neural network Module in PyTorch\n",
    "#Our model is composed of an embedding (neural network) and a MuyGPs Gaussian process layer.\n",
    "#The embedding includes linear layers and ReLU activation functions.\n",
    "\n",
    "class SVDKMuyGPs(nn.Module):\n",
    "\n",
    "    def __init__(self,num_models,kernel_eps,nu,length_scale,batch_indices,batch_nn_indices,batch_targets,batch_nn_targets):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Sequential(\n",
    "        nn.Linear(28**2,400),\n",
    "        nn.ReLU(1),\n",
    "        nn.Linear(400,100),\n",
    "         nn.ReLU(1),\n",
    "        )\n",
    "        self.eps = kernel_eps\n",
    "        self.nu = nu\n",
    "        self.length_scale = length_scale\n",
    "        self.batch_indices = batch_indices\n",
    "        self.num_models = num_models\n",
    "        self.batch_nn_indices = batch_nn_indices\n",
    "        self.batch_targets = batch_targets\n",
    "        self.batch_nn_targets = batch_nn_targets\n",
    "        #self.GP_layer = MultivariateMuyGPs_layer(self.num_models,self.eps,self.nu,self.length_scale,self.batch_indices,self.batch_nn_indices,self.batch_targets,self.batch_nn_targets)\n",
    "        self.GP_layer = MuyGPs_layer(kernel_eps,nu,length_scale,batch_indices,batch_nn_indices,batch_targets,batch_nn_targets)\n",
    "   \n",
    "    def forward(self,x): \n",
    "        predictions = self.embedding(x)\n",
    "        predictions,variances,sigma_sq = self.GP_layer(predictions)\n",
    "        return predictions,variances,sigma_sq"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14df56f9",
   "metadata": {},
   "source": [
    "# Train Deep Kernel MuyGPs model using low-level API implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb287061",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Construct Deep Kernel model via SVDKMuyGPs object. \n",
    "model = SVDKMuyGPs(num_models=num_classes,kernel_eps=1e-6,nu=0.5,length_scale=1.0,batch_indices=batch_indices,batch_nn_indices=batch_nn_indices,batch_targets=batch_targets,batch_nn_targets=batch_nn_targets)\n",
    "#model = SVDKMuyGPs(num_models=num_classes,kernel_eps=1e-3*torch.ones(num_classes),nu=1/2*torch.ones(num_classes),length_scale=2.0*torch.ones(num_classes),batch_indices=batch_indices,batch_nn_indices=batch_nn_indices,batch_targets=batch_targets,batch_nn_targets=batch_nn_targets)\n",
    "if torch.cuda.is_available():\n",
    "    model = model.cuda()\n",
    "training_iterations = 10\n",
    "\n",
    "#Use the adam optimizer with an initial learning rate of 1e-3 and an exponential decay rate of 0.97.\n",
    "optimizer = torch.optim.Adam([\n",
    "    {'params': model.parameters()},\n",
    "], lr=1e-3) \n",
    "scheduler = ExponentialLR(optimizer,gamma=0.97)\n",
    "mse_loss = nn.MSELoss()\n",
    "l1_loss = nn.L1Loss()\n",
    "bce_loss = nn.BCELoss()\n",
    "ce_loss = nn.CrossEntropyLoss()\n",
    "\n",
    "#Build standard PyTorch training loop function\n",
    "\n",
    "def train(nbrs_lookup):\n",
    "    for i in range(training_iterations):\n",
    "        model.train()\n",
    "        optimizer.zero_grad()\n",
    "        predictions,variances,sigma_sq = model(train_features)\n",
    "        \n",
    "        #Use Cross-Entropy Loss since this is a classification problem\n",
    "        \n",
    "        loss = ce_loss(predictions,batch_targets)\n",
    "        loss.backward()      \n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "        if np.mod(i,1) == 0:\n",
    "            print('Iter %d/%d - Loss: %.10f' % (i + 1, training_iterations, loss.item()))\n",
    "            model.eval()\n",
    "            nbrs_lookup = NN_Wrapper(model.embedding(train_features).detach().numpy(), nn_count, nn_method=\"hnsw\")\n",
    "            batch_nn_indices,_ = nbrs_lookup._get_nns(model.embedding(batch_features).detach().numpy(),nn_count=nn_count)\n",
    "            batch_nn_indices = torch.from_numpy(batch_nn_indices.astype(np.int64))\n",
    "            batch_nn_targets = train_responses[batch_nn_indices, :]  \n",
    "            model.batch_nn_indices = batch_nn_indices\n",
    "            model.batch_nn_targets = batch_nn_targets\n",
    "        torch.cuda.empty_cache()\n",
    "    nbrs_lookup = NN_Wrapper(model.embedding(train_features).detach().numpy(), nn_count, nn_method=\"hnsw\")\n",
    "    batch_nn_indices,_ = nbrs_lookup._get_nns(model.embedding(batch_features).detach().numpy(),nn_count=nn_count)\n",
    "    batch_nn_indices = torch.from_numpy(batch_nn_indices.astype(np.int64))\n",
    "    batch_nn_targets = train_responses[batch_nn_indices, :]\n",
    "    model.batch_nn_indices = batch_nn_indices\n",
    "    model.batch_nn_targets = batch_nn_targets\n",
    "    return nbrs_lookup, model\n",
    "\n",
    "nbrs_lookup, model_trained = train(nbrs_lookup)\n",
    "model_trained.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4f54d60",
   "metadata": {},
   "source": [
    "Predict test responses using trained model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "101aa630",
   "metadata": {},
   "outputs": [],
   "source": [
    "from MuyGPyS.examples.muygps_torch import predict_model\n",
    "predictions,variances,sigma_sq = predict_model(model=model_trained,test_features=test_features,train_features=train_features,train_responses=train_responses,nbrs_lookup=nbrs_lookup,nn_count=nn_count)\n",
    "\n",
    "print(\"MNIST Prediction Accuracy Using Low-Level Torch Implementation:\")\n",
    "print((torch.sum(torch.argmax(predictions,dim=1)==torch.argmax(test_responses,dim=1))/10000).numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eeb5469a",
   "metadata": {},
   "source": [
    "# Train Deep Kernel MuyGPs model using high-level API function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbf19103",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import high-level API function train_deep_kernel_muygps \n",
    "from MuyGPyS.examples.muygps_torch import train_deep_kernel_muygps\n",
    "\n",
    "#Use leave-one-out-likelihood loss function to train model\n",
    "model = SVDKMuyGPs(num_models=num_classes,kernel_eps=1e-6,nu=0.5,length_scale=1.0,batch_indices=batch_indices,batch_nn_indices=batch_nn_indices,batch_targets=batch_targets,batch_nn_targets=batch_nn_targets)\n",
    "\n",
    "nbrs_lookup, model_trained = train_deep_kernel_muygps(\n",
    "    model=model,\n",
    "    train_features=train_features,\n",
    "    train_responses=train_responses,\n",
    "    batch_indices=batch_indices,\n",
    "    nbrs_lookup=nbrs_lookup,\n",
    "    training_iterations=10,\n",
    "    optimizer_method=torch.optim.Adam,\n",
    "    learning_rate=1e-3,\n",
    "    scheduler_decay=0.97,\n",
    "    loss_function=\"ce\",\n",
    "    update_frequency=1,\n",
    "    verbose=True,\n",
    ")\n",
    "\n",
    "model_trained.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39bc45bd",
   "metadata": {},
   "source": [
    "Predict test responses using trained model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "201e4230",
   "metadata": {},
   "outputs": [],
   "source": [
    "from MuyGPyS.examples.muygps_torch import predict_model\n",
    "predictions,variances,sigma_sq = predict_model(model=model_trained,test_features=test_features,train_features=train_features,train_responses=train_responses,nbrs_lookup=nbrs_lookup,nn_count=nn_count)\n",
    "\n",
    "print(\"MNIST Prediction Accuracy Using High-Level Training API:\")\n",
    "print((torch.sum(torch.argmax(predictions,dim=1)==torch.argmax(test_responses,dim=1))/10000).numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d42e147a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(signature(ce_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a92de34c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "434749ae7207e94f9d6928c9f347c2cd1a679cf18b55a36c093c3f406aed8e17"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
