{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copyright 2021-2023 Lawrence Livermore National Security, LLC and other MuyGPyS\n",
    "Project Developers. See the top-level COPYRIGHT file for details.\n",
    "\n",
    "SPDX-License-Identifier: MIT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# One-Line Regression Workflow\n",
    "\n",
    "This notebook walks through the same regression workflow as \n",
    "[the univariate regression tutorial](univariate_regression_tutorial.ipynb).\n",
    "\n",
    "This workflow differs from the \n",
    "[tutorial](univariate_regression_tutorial.ipynb)\n",
    "by making use of a \n",
    "[high-level API](../MuyGPyS/examples/regress.rst)\n",
    "that automates all of the steps contained therein.\n",
    "`MuyGPyS.examples` automates a small number of such workflows.\n",
    "While it is recommended to stick to the lower-level API, the supported high-level APIs are useful for the simple applications that they support. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from MuyGPyS._test.gp import benchmark_sample, benchmark_sample_full, BenchmarkGP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will set a random seed here for consistency when building docs.\n",
    "In practice we would not fix a seed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We perform the same operations to sample a curve from a conventional GP as described in the \n",
    "[tutorial notebook](univariate_regression_tutorial.ipynb)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lb = -10.0\n",
    "ub = 10.0\n",
    "data_count = 5001\n",
    "train_step = 10\n",
    "x = np.linspace(lb, ub, data_count).reshape(data_count, 1)\n",
    "test_features = x[np.mod(np.arange(data_count), train_step) != 0, :]\n",
    "train_features = x[::train_step, :]\n",
    "test_count, _ = test_features.shape\n",
    "train_count, _ = train_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from MuyGPyS.gp.distortion import IsotropicDistortion, NullDistortion\n",
    "from MuyGPyS.gp.kernels import Hyperparameter, Matern\n",
    "from MuyGPyS.gp.noise import HomoscedasticNoise\n",
    "nugget_var = 1e-14\n",
    "fixed_length_scale = 1.0\n",
    "gp = BenchmarkGP(\n",
    "    Matern(\n",
    "        nu=Hyperparameter(2.0),\n",
    "        length_scale=Hyperparameter(fixed_length_scale),\n",
    "        metric=NullDistortion(\"l2\"),\n",
    "    ),\n",
    "    eps=HomoscedasticNoise(nugget_var),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = benchmark_sample(gp, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_responses = y[np.mod(np.arange(data_count), train_step) != 0, :]\n",
    "measurement_eps = 1e-5\n",
    "train_responses = y[::train_step, :] + np.random.normal(0, measurement_eps, size=(train_count,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, 1, figsize=(15, 11))\n",
    "\n",
    "axes[0].set_title(\"Sampled Curve\", fontsize=24)\n",
    "axes[0].set_xlabel(\"Feature Domain\", fontsize=20)\n",
    "axes[0].set_ylabel(\"Response Range\", fontsize=20)\n",
    "axes[0].plot(train_features, train_responses, \"k*\", label=\"perturbed train response\")\n",
    "axes[0].plot(test_features, test_responses, \"g-\", label=\"test response\")\n",
    "axes[0].legend(fontsize=20) \n",
    "\n",
    "vis_subset_size = 10\n",
    "mid = int(train_count / 2)\n",
    "\n",
    "axes[1].set_title(\"Sampled Curve (subset)\", fontsize=24)\n",
    "axes[1].set_xlabel(\"Feature Domain\", fontsize=20)\n",
    "axes[1].set_ylabel(\"Response Range\", fontsize=20)\n",
    "axes[1].plot(\n",
    "    train_features[mid:mid + vis_subset_size], \n",
    "    train_responses[mid:mid + vis_subset_size], \n",
    "    \"k*\", label=\"perturbed train response\"\n",
    ")\n",
    "axes[1].plot(\n",
    "    test_features[mid * (train_step - 1):mid * (train_step - 1) + (vis_subset_size * (train_step - 1))], \n",
    "    test_responses[mid * (train_step - 1):mid * (train_step - 1) + (vis_subset_size * (train_step - 1))], \n",
    "    \"g-\", label=\"test response\"\n",
    ")\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " We now set our nearest neighbor index and kernel parameters. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn_kwargs = {\"nn_method\": \"exact\", \"algorithm\": \"ball_tree\"}\n",
    "k_kwargs = {\n",
    "    \"kernel\": Matern(\n",
    "        nu=Hyperparameter(\"log_sample\", (0.1, 5.0)),\n",
    "        length_scale=Hyperparameter(fixed_length_scale),\n",
    "        metric=IsotropicDistortion(\"l2\")\n",
    "    ),\n",
    "    \"eps\": HomoscedasticNoise(measurement_eps),\n",
    "}\n",
    "opt_kwargs = {\"random_state\": 1, \"init_points\": 5, \"n_iter\": 20}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we run [do_regress()](../MuyGPyS/examples/regress.rst).\n",
    "This function entirely instruments a simple regression workflow, with several tunable options.\n",
    "Most of the keyword arguments in this example are specified at their default values, so in practice this call need not be so verbose. \n",
    "\n",
    "The kwarg `opt_method` indicates which optimization method to use.\n",
    "In this example, we have used `\"bayesian\"`, which will use the corresponding kwargs given by `opt_kwargs`. \n",
    "The other currently supported option, `\"scipy\"`, expects no additional kwargs and so the user can safely omit `opt_kwargs`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from MuyGPyS.examples.regress import do_regress\n",
    "\n",
    "muygps, nbrs_lookup, predictions, variances = do_regress(\n",
    "    test_features,\n",
    "    train_features,\n",
    "    train_responses,\n",
    "    nn_count=30,\n",
    "    batch_count=train_count,\n",
    "    loss_method=\"mse\",\n",
    "    obj_method=\"loo_crossval\",\n",
    "    opt_method=\"bayesian\",\n",
    "    sigma_method=\"analytic\",\n",
    "    k_kwargs=k_kwargs,\n",
    "    nn_kwargs=nn_kwargs,\n",
    "    opt_kwargs=opt_kwargs,\n",
    "    verbose=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We here evaluate our prediction performance in the same manner as in the \n",
    "[tutorial](univariate_regression_tutorial.ipynb).\n",
    "We report the RMSE, mean diagonal posterior variance, the mean 95% confidence interval size, and the coverage, which ideally should be near 95%. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from MuyGPyS.optimize.loss import mse_fn\n",
    "\n",
    "confidence_intervals = np.sqrt(variances) * 1.96\n",
    "coverage = (\n",
    "    np.count_nonzero(\n",
    "        np.abs(test_responses - predictions)\n",
    "        < confidence_intervals\n",
    "    )\n",
    "    / test_count\n",
    ")\n",
    "confidence_intervals = confidence_intervals.reshape((test_count,))\n",
    "print(f\"RMSE: {np.sqrt(mse_fn(predictions, test_responses))}\")\n",
    "print(f\"mean diagonal variance: {np.mean(variances)}\")\n",
    "print(f\"mean confidence interval size: {np.mean(confidence_intervals * 2)}\")\n",
    "print(f\"coverage: {coverage}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also produce the same plots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, 1, figsize=(15, 11))\n",
    "\n",
    "axes[0].set_title(\"Sampled Curve\", fontsize=24)\n",
    "axes[0].set_xlabel(\"Feature Domain\", fontsize=20)\n",
    "axes[0].set_ylabel(\"Response Range\", fontsize=20)\n",
    "axes[0].plot(train_features, train_responses, \"k*\", label=\"perturbed train response\")\n",
    "axes[0].plot(test_features, test_responses, \"g-\", label=\"test response\")\n",
    "axes[0].plot(test_features, predictions, \"r--\", label=\"test predictions\")\n",
    "axes[0].fill_between(\n",
    "    test_features[:, 0], \n",
    "    (predictions[:, 0] - confidence_intervals),\n",
    "    (predictions[:, 0] + confidence_intervals),\n",
    "    facecolor=\"red\",\n",
    "    alpha=0.25,\n",
    "    label=\"95% Confidence Interval\",\n",
    ")\n",
    "axes[0].legend(fontsize=20)\n",
    "\n",
    "axes[1].set_title(\"Sampled Curve (subset)\", fontsize=24)\n",
    "axes[1].set_xlabel(\"Feature Domain\", fontsize=20)\n",
    "axes[1].set_ylabel(\"Response Range\", fontsize=20)\n",
    "axes[1].plot(\n",
    "    train_features[mid:mid + vis_subset_size], \n",
    "    train_responses[mid:mid + vis_subset_size], \n",
    "    \"k*\", label=\"perturbed train response\"\n",
    ")\n",
    "axes[1].plot(\n",
    "    test_features[mid * (train_step - 1):mid * (train_step - 1) + (vis_subset_size * (train_step - 1))], \n",
    "    test_responses[mid * (train_step - 1):mid * (train_step - 1) + (vis_subset_size * (train_step - 1))], \n",
    "    \"g-\", label=\"test response\"\n",
    ")\n",
    "axes[1].plot(\n",
    "    test_features[mid * (train_step - 1):mid * (train_step - 1) + (vis_subset_size * (train_step - 1))], \n",
    "    predictions[mid * (train_step - 1):mid * (train_step - 1) + (vis_subset_size * (train_step - 1))],\n",
    "    \"r--\", label=\"test predictions\")\n",
    "axes[1].fill_between(\n",
    "    test_features[mid * (train_step - 1):mid * (train_step - 1) + (vis_subset_size * (train_step - 1))][:, 0], \n",
    "    (predictions[:, 0] - confidence_intervals)[mid * (train_step - 1):mid * (train_step - 1) + (vis_subset_size * (train_step - 1))],\n",
    "    (predictions[:, 0] + confidence_intervals)[mid * (train_step - 1):mid * (train_step - 1) + (vis_subset_size * (train_step - 1))],\n",
    "    facecolor=\"red\",\n",
    "    alpha=0.25,\n",
    "    label=\"95% Confidence Interval\",\n",
    ")\n",
    "axes[1].legend(fontsize=20)\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "@webio": {
   "lastCommId": null,
   "lastKernelId": null
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
