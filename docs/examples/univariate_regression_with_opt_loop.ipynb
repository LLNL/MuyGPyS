{
    "cells": [
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Copyright 2021-2023 Lawrence Livermore National Security, LLC and other MuyGPyS\n",
                "Project Developers. See the top-level COPYRIGHT file for details.\n",
                "\n",
                "SPDX-License-Identifier: MIT"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Optimization loop chassis test\n",
                "\n",
                "This notebook walks through the `MuyGPyS` univariate regression tutorial using experimental optimaztion loop chassis. The goal is to recover the response on the held-out test data by training a univariate `MuyGPS` model on the perturbed training data with `length_scale` and `measurement_noise` known, while `nu` smoothness hyperparameter is to be learned.\n",
                "1. Sample a curve from a conventional GP\n",
                "2. Construct nearest neighbor lookups\n",
                "3. Create duplicate of `MuyGPyS` object used in `sampler` to be used for training and inference\n",
                "4. Call `optimize_from_tensors_mini_batch` to sample batches of data, construct tensors, and run bayes optimization using numpy math backend"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import numpy as np\n",
                "\n",
                "from utils import UnivariateSampler, print_results\n",
                "\n",
                "from MuyGPyS.gp import MuyGPS\n",
                "from MuyGPyS.gp.distortion import IsotropicDistortion, l2\n",
                "from MuyGPyS.gp.hyperparameter import ScalarHyperparameter\n",
                "from MuyGPyS.gp.kernels import Matern\n",
                "from MuyGPyS.gp.noise import HomoscedasticNoise\n",
                "from MuyGPyS.gp.tensors import make_predict_tensors\n",
                "from MuyGPyS.optimize.experimental.chassis import optimize_from_tensors_mini_batch\n",
                "from MuyGPyS.neighbors import NN_Wrapper\n",
                "\n",
                "\n",
                "np.random.seed(0)\n",
                "lb = -10.0\n",
                "ub = 10.0\n",
                "data_count = 5001\n",
                "train_step = 10\n",
                "nugget_noise = HomoscedasticNoise(1e-14)\n",
                "measurement_noise = HomoscedasticNoise(1e-5)\n",
                "sim_length_scale = ScalarHyperparameter(1.0)\n",
                "sim_nu = ScalarHyperparameter(2.0)\n",
                "sampler = UnivariateSampler(\n",
                "    lb=lb,\n",
                "    ub=ub,\n",
                "    data_count=data_count,\n",
                "    train_step=train_step,\n",
                "    kernel=Matern(\n",
                "        nu=sim_nu,\n",
                "        metric=IsotropicDistortion(\n",
                "            l2,\n",
                "            length_scale=sim_length_scale,\n",
                "        ),\n",
                "    ),\n",
                "    eps=nugget_noise,\n",
                "    measurement_eps=measurement_noise,\n",
                ")\n",
                "train_features, test_features = sampler.features()\n",
                "train_responses, test_responses = sampler.sample()\n",
                "# sampler.plot_sample()\n",
                "\n",
                "nn_count = 30\n",
                "nbrs_lookup = NN_Wrapper(train_features, nn_count, nn_method=\"exact\", algorithm=\"ball_tree\")\n",
                "\n",
                "exp_nu = ScalarHyperparameter(\"log_sample\", (0.1, 5.0))\n",
                "muygps = MuyGPS(\n",
                "    kernel=Matern(\n",
                "        nu=exp_nu,\n",
                "        metric=IsotropicDistortion(\n",
                "            l2,\n",
                "            length_scale=sim_length_scale,\n",
                "        ),\n",
                "    ),\n",
                "    eps=measurement_noise,\n",
                ")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Validate using all training data."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "muygps_bayes_mse = optimize_from_tensors_mini_batch(\n",
                "    muygps,\n",
                "    train_features,\n",
                "    train_responses,\n",
                "    nbrs_lookup,\n",
                "    batch_count=sampler.train_count,\n",
                "    train_count=sampler.train_count,\n",
                "    num_epochs=1,\n",
                "    batch_features=None,\n",
                "    loss_method=\"mse\",\n",
                "    obj_method=\"loo_crossval\",\n",
                "    sigma_method=\"analytic\",\n",
                "    verbose=True,\n",
                "    random_state=1,\n",
                "    init_points=5,\n",
                "    n_iter=20,\n",
                ")\n",
                "print(f\"\\n`loss_method` 'mse' `nu` {muygps_bayes_mse.kernel.nu()} `sigma_sq` {muygps_bayes_mse.sigma_sq()}\")\n",
                "\n",
                "muygps_bayes_lool = optimize_from_tensors_mini_batch(\n",
                "    muygps,\n",
                "    train_features,\n",
                "    train_responses,\n",
                "    nbrs_lookup,\n",
                "    batch_count=sampler.train_count,\n",
                "    train_count=sampler.train_count,\n",
                "    num_epochs=1,\n",
                "    batch_features=None,\n",
                "    loss_method=\"lool\",\n",
                "    obj_method=\"loo_crossval\",\n",
                "    sigma_method=\"analytic\",\n",
                "    verbose=True,\n",
                "    random_state=1,\n",
                "    init_points=5,\n",
                "    n_iter=20,\n",
                ")\n",
                "print(f\"\\n`loss_method` 'lool' `nu` {muygps_bayes_lool.kernel.nu()} `sigma_sq` {muygps_bayes_lool.sigma_sq()}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Test optimization loop chassis using sample batch size = 100."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "batch_count=100\n",
                "train_count=sampler.train_count\n",
                "num_epochs=int(sampler.train_count / batch_count)\n",
                "\n",
                "muygps_bayes_mse = optimize_from_tensors_mini_batch(\n",
                "    muygps,\n",
                "    train_features,\n",
                "    train_responses,\n",
                "    nbrs_lookup,\n",
                "    batch_count=batch_count,\n",
                "    train_count=train_count,\n",
                "    num_epochs=num_epochs,\n",
                "    batch_features=None,\n",
                "    loss_method=\"mse\",\n",
                "    obj_method=\"loo_crossval\",\n",
                "    sigma_method=\"analytic\",\n",
                "    verbose=True,\n",
                "    random_state=1,\n",
                "    init_points=5,\n",
                "    n_iter=20,\n",
                ")\n",
                "print(f\"\\n`loss_method` 'mse' `nu` {muygps_bayes_mse.kernel.nu()} `sigma_sq` {muygps_bayes_mse.sigma_sq()}\")\n",
                "\n",
                "muygps_bayes_lool = optimize_from_tensors_mini_batch(\n",
                "    muygps,\n",
                "    train_features,\n",
                "    train_responses,\n",
                "    nbrs_lookup,\n",
                "    batch_count=batch_count,\n",
                "    train_count=train_count,\n",
                "    num_epochs=num_epochs,\n",
                "    batch_features=None,\n",
                "    loss_method=\"lool\",\n",
                "    obj_method=\"loo_crossval\",\n",
                "    sigma_method=\"analytic\",\n",
                "    verbose=True,\n",
                "    random_state=1,\n",
                "    init_points=5,\n",
                "    n_iter=20,\n",
                ")\n",
                "print(f\"\\n`loss_method` 'lool' `nu` {muygps_bayes_lool.kernel.nu()} `sigma_sq` {muygps_bayes_lool.sigma_sq()}\")"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Predict the response of test data.\n",
                "1. Find the indices of the nearest neighbors of test elements\n",
                "2. Make distance difference and target tensors for test data\n",
                "3. Create kernel tensors and find posterior means and variances associated with each training prediction\n",
                "4. Evaluate prediction performance in terms of RMSE, mean diagonal posterior variance, the mean 95% confidence interval size, and the coverage, which ideally should be near 95%. "
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "test_count, _ = test_features.shape\n",
                "indices = np.arange(test_count)\n",
                "test_nn_indices, _ = nbrs_lookup.get_nns(test_features)\n",
                "\n",
                "(\n",
                "    test_crosswise_diffs,\n",
                "    test_pairwise_diffs,\n",
                "    test_nn_targets,\n",
                ") = make_predict_tensors(\n",
                "    indices,\n",
                "    test_nn_indices,\n",
                "    test_features,\n",
                "    train_features,\n",
                "    train_responses,\n",
                ")\n",
                "\n",
                "bayes_Kcross = muygps_bayes_mse.kernel(test_crosswise_diffs)\n",
                "bayes_K = muygps_bayes_mse.kernel(test_pairwise_diffs)\n",
                "bayes_predictions = muygps_bayes_mse.posterior_mean(\n",
                "    bayes_K, bayes_Kcross, test_nn_targets\n",
                ")\n",
                "bayes_variances = muygps_bayes_mse.posterior_variance(\n",
                "    bayes_K, bayes_Kcross\n",
                ")\n",
                "\n",
                "bayes_confidence_intervals = np.sqrt(bayes_variances) * 1.96\n",
                "bayes_coverage = (\n",
                "    np.count_nonzero(\n",
                "        np.abs(test_responses - bayes_predictions) < bayes_confidence_intervals\n",
                "    ) / test_count\n",
                ")\n",
                "print_results(\"bayes mse\", test_responses, bayes_predictions, bayes_variances, bayes_confidence_intervals, bayes_coverage)\n",
                "# sampler.plot_results(bayes_predictions, bayes_confidence_intervals)\n"
            ]
        }
    ],
    "metadata": {
        "@webio": {
            "lastCommId": null,
            "lastKernelId": null
        },
        "kernelspec": {
            "display_name": "Python 3 (ipykernel)",
            "language": "python",
            "name": "python3"
        },
        "toc": {
            "base_numbering": 1,
            "nav_menu": {},
            "number_sections": true,
            "sideBar": true,
            "skip_h1_title": false,
            "title_cell": "Table of Contents",
            "title_sidebar": "Contents",
            "toc_cell": false,
            "toc_position": {},
            "toc_section_display": true,
            "toc_window_display": false
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}
