{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copyright 2021-2023 Lawrence Livermore National Security, LLC and other MuyGPyS\n",
    "Project Developers. See the top-level COPYRIGHT file for details.\n",
    "\n",
    "SPDX-License-Identifier: MIT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from typing import Callable\n",
    "\n",
    "from MuyGPyS.gp.distortion import AnisotropicDistortion, l2\n",
    "from MuyGPyS.gp.hyperparameter import ScalarHyperparameter\n",
    "from MuyGPyS.neighbors import NN_Wrapper\n",
    "import MuyGPyS._src.math as mm\n",
    "\n",
    "\n",
    "np.random.seed(0)\n",
    "\n",
    "def _test_mask(data_count, train_step):\n",
    "    return np.mod(np.arange(data_count), train_step) != 0\n",
    "\n",
    "def _train_mask(train_step):\n",
    "    return slice(None, None, train_step)\n",
    "\n",
    "def _get_length_scale_array(\n",
    "    array_fn: Callable,\n",
    "    target_shape: mm.ndarray,\n",
    "    **length_scales,\n",
    ") -> mm.ndarray:\n",
    "    AnisotropicDistortion._lengths_agree(\n",
    "        len(length_scales), target_shape[-1]\n",
    "    )\n",
    "    # make sure each length_scale array is broadcastable when its shape is (batch_count,)\n",
    "    shape = (1,) * (len(target_shape) - 2) + (-1,)\n",
    "    return array_fn(\n",
    "        [mm.reshape(value, shape) for value in length_scales.values()]\n",
    "    ).T\n",
    "\n",
    "def _anisotropic_dist_fn(\n",
    "    diffs: mm.ndarray, **length_scales\n",
    ") -> mm.ndarray:\n",
    "    length_scale_array = _get_length_scale_array(\n",
    "        mm.array, diffs.shape, **length_scales\n",
    "    )\n",
    "    return l2(diffs / length_scale_array)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1D Univariate\n",
    "print(\"1D\")\n",
    "data_count = 20#5001\n",
    "train_step = 2#10\n",
    "x = np.linspace(0, data_count, data_count)#1, data_count)\n",
    "x = x.reshape(data_count, 1)\n",
    "# print(f\"features x {x.shape} {x}\")\n",
    "test_mask = _test_mask(data_count, train_step)\n",
    "train_mask  = _train_mask(train_step)\n",
    "test_features = x[test_mask, :]\n",
    "train_features = x[train_mask, :]\n",
    "print(f\"train features {train_features.shape} {train_features}\")\n",
    "test_count, _ = test_features.shape\n",
    "train_count, _ = train_features.shape\n",
    "\n",
    "# 1D distance scaling\n",
    "sim_length_scale0 = ScalarHyperparameter(0.1)   # HP distance scaling dim 0\n",
    "sim_length_scale1 = ScalarHyperparameter(0.5)   # HP distance scaling dim 1\n",
    "features_aniso_dist_scaled = _anisotropic_dist_fn(\n",
    "    train_features,\n",
    "    length_scale0=sim_length_scale0(),\n",
    ")\n",
    "features_aniso_dist_scaled = features_aniso_dist_scaled.reshape(train_count, 1)\n",
    "print(f\"train features scaled {features_aniso_dist_scaled.shape} {features_aniso_dist_scaled}\")\n",
    "\n",
    "# 1D Nearest Neighbors\n",
    "nn_count = 3#30\n",
    "batch_count = train_count\n",
    "nbrs_lookup = NN_Wrapper( # sklearn Euclidean distance\n",
    "    train_features,\n",
    "    nn_count,\n",
    "    nn_method=\"exact\",\n",
    "    algorithm=\"ball_tree\")\n",
    "if train_count > batch_count:\n",
    "    batch_indices = mm.iarray(\n",
    "        np.random.choice(train_count, batch_count, replace=False)\n",
    "    )\n",
    "else:\n",
    "    batch_indices = mm.arange(train_count, dtype=mm.itype)\n",
    "batch_nn_indices, batch_nn_dists = nbrs_lookup.get_batch_nns(batch_indices) # F2\n",
    "print(f\"indices {batch_nn_indices.shape} {batch_nn_indices}\")\n",
    "print(f\"dists {batch_nn_dists.shape} {batch_nn_dists}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2D Univariate\n",
    "print(\"\\n2D\")\n",
    "points_per_dim = 6#60\n",
    "data_count = points_per_dim**2\n",
    "train_step = 2#13\n",
    "x = np.linspace(0, points_per_dim, points_per_dim)#1, points_per_dim)\n",
    "xx, yy = np.meshgrid(x, x)\n",
    "xs = np.array(\n",
    "    [\n",
    "        [xx[i, j], yy[i, j]]\n",
    "        for i in range(points_per_dim)\n",
    "        for j in range(points_per_dim)\n",
    "    ]\n",
    ")\n",
    "# print(f\"features x  {x.shape} {x}\")\n",
    "# print(f\"features xx {xx.shape} {xx}\")\n",
    "# print(f\"features yy {yy.shape} {yy}\")\n",
    "# print(f\"features xs {xs.shape} {xs}\")\n",
    "test_mask = _test_mask(data_count, train_step)\n",
    "train_mask  = _train_mask(train_step)\n",
    "test_features = xs[test_mask, :]\n",
    "train_features = xs[train_mask, :]\n",
    "test_count, _ = test_features.shape\n",
    "train_count, _ = train_features.shape\n",
    "print(f\"train features {train_features.shape} {train_features}\")\n",
    "\n",
    "# 2D distance scaling\n",
    "sim_length_scale0 = ScalarHyperparameter(0.1)   # HP distance scaling dim 0\n",
    "sim_length_scale1 = ScalarHyperparameter(0.5)   # HP distance scaling dim 1\n",
    "scales = _get_length_scale_array(mm.array, train_features.shape, length_scale0=sim_length_scale0(), length_scale1=sim_length_scale1())\n",
    "print (scales)\n",
    "train_features_scaled = train_features / scales\n",
    "print (train_features_scaled)\n",
    "\n",
    "# 2D Nearest Neighbors\n",
    "nn_count = 3#30\n",
    "batch_count = train_count\n",
    "nbrs_lookup = NN_Wrapper( # sklearn Euclidean distance\n",
    "    train_features_scaled,\n",
    "    nn_count,\n",
    "    nn_method=\"exact\",\n",
    "    algorithm=\"ball_tree\")\n",
    "if train_count > batch_count:\n",
    "    batch_indices = mm.iarray(\n",
    "        np.random.choice(train_count, batch_count, replace=False)\n",
    "    )\n",
    "else:\n",
    "    batch_indices = mm.arange(train_count, dtype=mm.itype)\n",
    "batch_nn_indices, batch_nn_dists = nbrs_lookup.get_batch_nns(batch_indices) # F2\n",
    "print(f\"indices {batch_nn_indices.shape} {batch_nn_indices}\")\n",
    "print(f\"dists {batch_nn_dists.shape} {batch_nn_dists}\")\n"
   ]
  }
 ],
 "metadata": {
  "@webio": {
   "lastCommId": null,
   "lastKernelId": null
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
