{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copyright 2021-2023 Lawrence Livermore National Security, LLC and other MuyGPyS\n",
    "Project Developers. See the top-level COPYRIGHT file for details.\n",
    "\n",
    "SPDX-License-Identifier: MIT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Anisotropic tutorial with optimization loop chassis\n",
    "\n",
    "This notebook walks through four experimental treatments using the optimaztion loop chassis and 2D Univariate Sampler used in the [Anisotropic Metric Tutorial](../docs/examples/anisotropic_tutorial.ipynb). The goal is increase accuracy of learned hyperparameters in order to best recover the response on the held-out test data by training a simple anisotropic `MuyGPS` model on the perturbed training data with smoothness hyperparameter known, while the two `distance scaling` hyperparameters are to be learned. Each iteration of the optimization loop we scale training features using learned length scale hyperparameters, update nearest neighbors lookup using sklearn, update objective function, and run bayes optimization using numpy math backend."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "for m in sys.modules.keys():\n",
    "    if m.startswith(\"Muy\"):\n",
    "        sys.modules.pop(m)\n",
    "%env MUYGPYS_BACKEND=numpy\n",
    "%env MUYGPYS_FTYPE=64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from MuyGPyS._test.sampler import UnivariateSampler2D\n",
    "\n",
    "from MuyGPyS.gp import MuyGPS\n",
    "from MuyGPyS.gp.deformation import Anisotropy, l2\n",
    "from MuyGPyS.gp.hyperparameter import AnalyticScale, Parameter\n",
    "from MuyGPyS.gp.kernels import Matern\n",
    "from MuyGPyS.gp.noise import HomoscedasticNoise\n",
    "from MuyGPyS.gp.tensors import make_predict_tensors\n",
    "from MuyGPyS.optimize.experimental.chassis import optimize_from_tensors_mini_batch\n",
    "from MuyGPyS.optimize.loss import mse_fn, lool_fn\n",
    "\n",
    "\n",
    "np.random.seed(0)\n",
    "\n",
    "points_per_dim = 100 # 60                       # Observations per dimension\n",
    "train_ratio = 0.1 # 0.05                        # Train/test data split\n",
    "nugget_noise = HomoscedasticNoise(1e-14)        # Assume no noise in truth\n",
    "measurement_noise = HomoscedasticNoise(1e-7)    # Noise to perturb train\n",
    "sim_smoothness = Parameter(1.5)                 # HP smoothness\n",
    "sim_length_scale0 = Parameter(0.1)              # HP distance scaling dim 0\n",
    "sim_length_scale1 = Parameter(0.5)              # HP distance scaling dim 1\n",
    "sampler = UnivariateSampler2D(\n",
    "    points_per_dim=points_per_dim,\n",
    "    train_ratio=train_ratio,\n",
    "    kernel=Matern(\n",
    "        smoothness=sim_smoothness,\n",
    "        deformation=Anisotropy(\n",
    "            l2,\n",
    "            length_scale0=sim_length_scale0,\n",
    "            length_scale1=sim_length_scale1,\n",
    "        ),\n",
    "    ),\n",
    "    noise=nugget_noise,\n",
    "    measurement_noise=measurement_noise,\n",
    ")\n",
    "train_features, test_features = sampler.features()\n",
    "train_responses, test_responses = sampler.sample()\n",
    "\n",
    "exp_length_scale0 = Parameter(\"log_sample\", (0.01, 1.0))\n",
    "exp_length_scale1 = Parameter(\"log_sample\", (0.01, 1.0))\n",
    "muygps = MuyGPS(\n",
    "    kernel=Matern(\n",
    "        smoothness=sim_smoothness,\n",
    "        deformation=Anisotropy(\n",
    "            l2,\n",
    "            length_scale0=exp_length_scale0,\n",
    "            length_scale1=exp_length_scale1,\n",
    "        ),\n",
    "    ),\n",
    "    noise=measurement_noise,\n",
    "    scale=AnalyticScale(),\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt_kwargs = {\n",
    "    \"loss_fn\": lool_fn,\n",
    "    \"verbose\": False,\n",
    "    \"random_state\": 1,\n",
    "    \"init_points\": 5,\n",
    "    \"n_iter\": 30,\n",
    "    \"allow_duplicate_points\": True,\n",
    "}\n",
    "\n",
    "opt_kwargs1b = {\n",
    "    \"loss_fn\": lool_fn,\n",
    "    \"verbose\": False,\n",
    "    \"random_state\": 1,\n",
    "    \"init_points\": 25,\n",
    "    \"n_iter\": 30,\n",
    "    \"allow_duplicate_points\": True,\n",
    "}\n",
    "\n",
    "train_table = [\n",
    "    [\n",
    "        \"treatment\",\n",
    "        \"time (s)\",\n",
    "        \"train size\",\n",
    "        \"batch size\", \n",
    "        \"num epochs\",\n",
    "        \"pts probed\",\n",
    "        \"opt steps\",\n",
    "        \"l.s.0 (p.e.) \",\n",
    "        \"l.s.1 (p.e.) \",\n",
    "        \"scale\",\n",
    "    ]\n",
    "]\n",
    "\n",
    "inference_table = [\n",
    "    [\n",
    "        \"treatment\",\n",
    "        \"RMSE\",\n",
    "        \"mean diag var\",\n",
    "        \"mean c.i. size \",\n",
    "        \"coverage\",\n",
    "    ]\n",
    "]\n",
    "\n",
    "inference_data = []\n",
    "\n",
    "def store_details(\n",
    "        name,\n",
    "        batch_size,\n",
    "        train_size,\n",
    "        epoch_count,\n",
    "        muygps_exp,\n",
    "        nbrs_lookup_final,\n",
    "        exec_time,\n",
    "        probe_count,\n",
    "        opt_steps,\n",
    "    ):\n",
    "\n",
    "    # Training results\n",
    "    learned_sim_length_scale0 = muygps_exp.kernel.deformation.length_scale['length_scale0']()\n",
    "    pe0 = abs(learned_sim_length_scale0 - sim_length_scale0()) / sim_length_scale0() * 100.0\n",
    "    learned_sim_length_scale1 = muygps_exp.kernel.deformation.length_scale['length_scale1']()\n",
    "    pe1 = abs(learned_sim_length_scale1 - sim_length_scale1()) / sim_length_scale1() * 100.0\n",
    "    ret = [\n",
    "        name,\n",
    "        f\"{exec_time:.6f}\",\n",
    "        f\"{train_size}\",\n",
    "        f\"{batch_size}\",\n",
    "        f\"{epoch_count}\",\n",
    "        f\"{probe_count}\",\n",
    "        f\"{opt_steps}\",\n",
    "        f\"{learned_sim_length_scale0:.4f} ({pe0:2.0f}%)\",\n",
    "        f\"{learned_sim_length_scale1:.4f} ({pe1:2.0f}%)\",\n",
    "        f\"{muygps_exp.scale()[0]:.4f}\",\n",
    "    ]\n",
    "    train_table.append(ret)\n",
    "\n",
    "    # Inference results\n",
    "    test_count, _ = test_features.shape\n",
    "    indices = np.arange(test_count)\n",
    "    test_nn_indices, _ = nbrs_lookup_final.get_nns(test_features)\n",
    "    (\n",
    "        test_crosswise_diffs,\n",
    "        test_pairwise_diffs,\n",
    "        test_nn_targets,\n",
    "    ) = make_predict_tensors(\n",
    "        indices,\n",
    "        test_nn_indices,\n",
    "        test_features,\n",
    "        train_features,\n",
    "        train_responses,\n",
    "    )\n",
    "    Kcross = muygps_exp.kernel(test_crosswise_diffs)\n",
    "    Kin = muygps_exp.kernel(test_pairwise_diffs)\n",
    "    predictions = muygps_exp.posterior_mean(Kin, Kcross, test_nn_targets)\n",
    "    variances = muygps_exp.posterior_variance(Kin, Kcross)\n",
    "    confidence_intervals = np.sqrt(variances) * 1.96\n",
    "    coverage = (\n",
    "        np.count_nonzero(\n",
    "            np.abs(test_responses - predictions) < confidence_intervals\n",
    "        ) / test_count\n",
    "    )\n",
    "    ret = [\n",
    "        name,\n",
    "        f\"{np.sqrt(mse_fn(predictions, test_responses)):.5f}\",\n",
    "        f\"{np.mean(variances):.5f}\",\n",
    "        f\"{np.mean(confidence_intervals * 2):.5f}\",\n",
    "        f\"{coverage:.5f}\",\n",
    "    ]    \n",
    "    inference_table.append(ret)\n",
    "    inference_data.append([predictions, confidence_intervals])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Treatment #1a (baseline) - brute force workflow following [Anisotropic Metric Tutorial](../docs/examples/anisotropic_tutorial.ipynb) using single optimization step with a single initial probe point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    muygps_optloop,\n",
    "    nbrs_lookup_final,\n",
    "    exec_time,\n",
    "    probe_count,\n",
    "    opt_steps,\n",
    ") = optimize_from_tensors_mini_batch(\n",
    "    muygps,\n",
    "    train_features,\n",
    "    train_responses,\n",
    "    nn_count=30,\n",
    "    batch_count=sampler.train_count,\n",
    "    train_count=sampler.train_count,\n",
    "    num_epochs=1,\n",
    "    keep_state=False,\n",
    "    probe_previous=False,\n",
    "    **opt_kwargs,\n",
    ")\n",
    "store_details(\n",
    "    \"single step\",\n",
    "    sampler.train_count,\n",
    "    sampler.train_count,\n",
    "    1,\n",
    "    muygps_optloop,\n",
    "    nbrs_lookup_final,\n",
    "    exec_time,\n",
    "    probe_count,\n",
    "    opt_steps,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Treatment #1b - baseline +  configured to exploit and explore same total points "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    muygps_optloop,\n",
    "    nbrs_lookup_final,\n",
    "    exec_time,\n",
    "    probe_count,\n",
    "    opt_steps,\n",
    ") = optimize_from_tensors_mini_batch(\n",
    "    muygps,\n",
    "    train_features,\n",
    "    train_responses,\n",
    "    nn_count=30,\n",
    "    batch_count=sampler.train_count,\n",
    "    train_count=sampler.train_count,\n",
    "    num_epochs=1,\n",
    "    keep_state=False,\n",
    "    probe_previous=False,\n",
    "    **opt_kwargs1b,\n",
    ")\n",
    "store_details(\n",
    "    \"single step+\",\n",
    "    sampler.train_count,\n",
    "    sampler.train_count,\n",
    "    1,\n",
    "    muygps_optloop,\n",
    "    nbrs_lookup_final,\n",
    "    exec_time,\n",
    "    probe_count,\n",
    "    opt_steps,\n",
    ")\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Treatment #2a (opt loop) - each loop interation create new optimizer instance, initialize with new objective function, and do not probe previous points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    muygps_optloop,\n",
    "    nbrs_lookup_final,\n",
    "    exec_time,\n",
    "    probe_count,\n",
    "    opt_steps,\n",
    ") = optimize_from_tensors_mini_batch(\n",
    "    muygps,\n",
    "    train_features,\n",
    "    train_responses,\n",
    "    nn_count=30,\n",
    "    batch_count=(int(sampler.train_count / 5)),\n",
    "    train_count=sampler.train_count,\n",
    "    num_epochs=5,\n",
    "    keep_state=False,\n",
    "    probe_previous=False,\n",
    "    **opt_kwargs,\n",
    ")\n",
    "store_details(\n",
    "    \"no probe\",\n",
    "    (int(sampler.train_count / 5)),\n",
    "    sampler.train_count,\n",
    "    5,\n",
    "    muygps_optloop,\n",
    "    nbrs_lookup_final,\n",
    "    exec_time,\n",
    "    probe_count,\n",
    "    opt_steps,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Treatment #2b (opt loop) - each loop interation create new optimizer instance, initialize with new objective function, and probe previous points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    muygps_optloop,\n",
    "    nbrs_lookup_final,\n",
    "    exec_time,\n",
    "    probe_count,\n",
    "    opt_steps,\n",
    ") = optimize_from_tensors_mini_batch(\n",
    "    muygps,\n",
    "    train_features,\n",
    "    train_responses,\n",
    "    nn_count=30,\n",
    "    batch_count=(int(sampler.train_count / 5)),\n",
    "    train_count=sampler.train_count,\n",
    "    num_epochs=5,\n",
    "    keep_state=False,\n",
    "    probe_previous=True,\n",
    "    **opt_kwargs,\n",
    ")\n",
    "store_details(\n",
    "    \"probe all\",\n",
    "    (int(sampler.train_count / 5)),\n",
    "    sampler.train_count,\n",
    "    5,\n",
    "    muygps_optloop,\n",
    "    nbrs_lookup_final,\n",
    "    exec_time,\n",
    "    probe_count,\n",
    "    opt_steps,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Treatment #2c (opt loop) - each loop interation reuse optimizer instance, set `BayesianOptimization.TargetSpace.target_function` to new objective function, and do not probe previous points "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    muygps_optloop,\n",
    "    nbrs_lookup_final,\n",
    "    exec_time,\n",
    "    probe_count,\n",
    "    opt_steps,\n",
    ") = optimize_from_tensors_mini_batch(\n",
    "    muygps,\n",
    "    train_features,\n",
    "    train_responses,\n",
    "    nn_count=30,\n",
    "    batch_count=sampler.train_count,\n",
    "    train_count=sampler.train_count,\n",
    "    num_epochs=5,\n",
    "    keep_state=True,\n",
    "    probe_previous=False,\n",
    "    **opt_kwargs,\n",
    ")\n",
    "store_details(\n",
    "    \"reuse opt\",\n",
    "    sampler.train_count,\n",
    "    sampler.train_count,\n",
    "    5,\n",
    "    muygps_optloop,\n",
    "    nbrs_lookup_final,\n",
    "    exec_time,\n",
    "    probe_count,\n",
    "    opt_steps,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training and inference results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print tables\n",
    "max_len = max(len(header) for header in train_table[0])\n",
    "sep = \"-\" * max_len\n",
    "for row in train_table:\n",
    "    print(\"|\".join(header.ljust(max_len) for header in row))\n",
    "    if row == train_table[0]:\n",
    "        print(\"|\".join(sep for _ in row))\n",
    "print(\"\\n\")\n",
    "max_len = max(len(header) for header in inference_table[0])\n",
    "sep = \"-\" * max_len\n",
    "for row in inference_table:\n",
    "    print(\"|\".join(header.ljust(max_len) for header in row))\n",
    "    if row == inference_table[0]:\n",
    "        print(\"|\".join(sep for _ in row))\n",
    "\n",
    "# Load results\n",
    "results = []\n",
    "for predictions, confidence_intervals in inference_data:\n",
    "    (\n",
    "        resl_im,\n",
    "        conf_im,\n",
    "        covr_im,\n",
    "        resl_mag,\n",
    "        conf_mag,\n",
    "        covr_mag,\n",
    "    ) = sampler._get_images(predictions, confidence_intervals)\n",
    "    results.append(\n",
    "        [resl_im, conf_im, covr_im, resl_mag, conf_mag, covr_mag,]\n",
    "    )\n",
    "\n",
    "# Plot residuals\n",
    "im = []\n",
    "fig, axes = plt.subplots(1, 5, figsize=(50, 7))\n",
    "for index, result in enumerate(results):\n",
    "    resl_im, _, _, resl_mag, _, _ = result\n",
    "    im.append(\n",
    "        axes[index].imshow(\n",
    "            resl_im,\n",
    "            vmin=-resl_mag,\n",
    "            vmax=resl_mag,\n",
    "            cmap=\"coolwarm\"\n",
    "        )\n",
    "    )\n",
    "    axes[index].set_title(train_table[index + 1][0], fontsize=20)\n",
    "fig.colorbar(im[0], ax=axes.ravel().tolist())\n",
    "fig.suptitle(\"Residual\", x=0.45, fontsize=26)\n",
    "axes[0].set_xlabel(\"Axis 0\", fontsize=20)\n",
    "axes[0].set_ylabel(\"Axis 1\", fontsize=20)\n",
    "plt.show()\n",
    "# Plot CI Magnitude\n",
    "im = []\n",
    "fig, axes = plt.subplots(1, 5, figsize=(50, 7))\n",
    "for index, result in enumerate(results):\n",
    "    _, conf_im, _, _, conf_mag, _ = result\n",
    "    im.append(\n",
    "        axes[index].imshow(\n",
    "            conf_im, vmin=0.0, vmax=conf_mag, cmap=\"inferno\"\n",
    "        )\n",
    "    )\n",
    "    axes[index].set_title(train_table[index + 1][0], fontsize=20)\n",
    "fig.colorbar(im[0], ax=axes.ravel().tolist())\n",
    "fig.suptitle(\"CI Magnitude\", x=0.45, fontsize=26)\n",
    "axes[0].set_xlabel(\"Axis 0\", fontsize=20)\n",
    "axes[0].set_ylabel(\"Axis 1\", fontsize=20)\n",
    "plt.show()\n",
    "# Plot |Residual| - CI\n",
    "im = []\n",
    "fig, axes = plt.subplots(1, 5, figsize=(50, 7))\n",
    "for index, result in enumerate(results):\n",
    "    _, _, covr_im, _, _, covr_mag = result\n",
    "    im.append(\n",
    "        axes[index].imshow(\n",
    "            covr_im, vmin=-covr_mag, vmax=covr_mag, cmap=\"coolwarm\"\n",
    "        )\n",
    "    )\n",
    "    axes[index].set_title(train_table[index + 1][0], fontsize=20)\n",
    "fig.colorbar(im[0], ax=axes.ravel().tolist())\n",
    "fig.suptitle(\"|Residual| - CI\", fontsize=26)\n",
    "axes[0].set_xlabel(\"Axis 0\", fontsize=20)\n",
    "axes[0].set_ylabel(\"Axis 1\", fontsize=20)\n",
    "# plt.tight_layout()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "@webio": {
   "lastCommId": null,
   "lastKernelId": null
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
