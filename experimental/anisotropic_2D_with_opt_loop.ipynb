{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copyright 2021-2023 Lawrence Livermore National Security, LLC and other MuyGPyS\n",
    "Project Developers. See the top-level COPYRIGHT file for details.\n",
    "\n",
    "SPDX-License-Identifier: MIT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Anisotropic tutorial with optimization loop chassis\n",
    "\n",
    "This notebook walks through four experimental treatments using the optimaztion loop chassis and 2D Univariate Sampler used in the [Anisotropic Metric Tutorial](../docs/examples/anisotropic_tutorial.ipynb). The goal is to recover the response on the held-out test data by training a simple anisotropic `MuyGPS` model on the perturbed training data with `nu` smoothness hyperparameter known, while the two `distance scaling` hyperparameters are to be learned. Each iteration of the optimization loop we scale training features using learned length scale hyperparameters, update nearest neighbors lookup using sklearn, update objective function, and run bayes optimization using numpy math backend. We start by:\n",
    "1. Sampling a 2D surface from a conventional GP\n",
    "2. Create duplicate of `MuyGPyS` object used in `sampler` to be used for training and inference\n",
    "3. Execute four treatments using `optimize_from_tensors_mini_batch`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import sys\n",
    "# for m in sys.modules.keys():\n",
    "#     if m.startswith(\"Muy\"):\n",
    "#         sys.modules.pop(m)\n",
    "# %env MUYGPYS_BACKEND=numpy\n",
    "# %env MUYGPYS_FTYPE=64\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from docs.examples.utils import UnivariateSampler2D\n",
    "\n",
    "from MuyGPyS.gp import MuyGPS\n",
    "from MuyGPyS.gp.distortion import AnisotropicDistortion, l2\n",
    "from MuyGPyS.gp.hyperparameter import ScalarHyperparameter\n",
    "from MuyGPyS.gp.kernels import Matern\n",
    "from MuyGPyS.gp.noise import HomoscedasticNoise\n",
    "from MuyGPyS.optimize.experimental.chassis import optimize_from_tensors_mini_batch\n",
    "\n",
    "\n",
    "np.random.seed(0)\n",
    "\n",
    "points_per_dim = 60                             # Observations per dimension\n",
    "train_step = 13                                 # Train/test data split\n",
    "nugget_noise = HomoscedasticNoise(1e-14)        # Assume no noise in truth\n",
    "measurement_noise = HomoscedasticNoise(1e-7)    # Noise to perturb train\n",
    "sim_nu = ScalarHyperparameter(1.5)              # HP smoothness\n",
    "sim_length_scale0 = ScalarHyperparameter(0.1)   # HP distance scaling dim 0\n",
    "sim_length_scale1 = ScalarHyperparameter(0.5)   # HP distance scaling dim 1\n",
    "sampler = UnivariateSampler2D(\n",
    "    points_per_dim=points_per_dim,\n",
    "    train_step=train_step,\n",
    "    kernel=Matern(\n",
    "        nu=sim_nu,\n",
    "        metric=AnisotropicDistortion(\n",
    "            l2,\n",
    "            length_scale0=sim_length_scale0,\n",
    "            length_scale1=sim_length_scale1,\n",
    "        ),\n",
    "    ),\n",
    "    eps=nugget_noise,\n",
    "    measurement_eps=measurement_noise,\n",
    ")\n",
    "train_features, test_features = sampler.features()\n",
    "train_responses, test_responses = sampler.sample()\n",
    "# TODO sampler.plot_sample()\n",
    "\n",
    "exp_length_scale0 = ScalarHyperparameter(\"log_sample\", (0.01, 1.0))\n",
    "exp_length_scale1 = ScalarHyperparameter(\"log_sample\", (0.01, 1.0))\n",
    "muygps = MuyGPS(\n",
    "    kernel=Matern(\n",
    "        nu=sim_nu,\n",
    "        metric=AnisotropicDistortion(\n",
    "            l2,\n",
    "            length_scale0=exp_length_scale0,\n",
    "            length_scale1=exp_length_scale1,\n",
    "        ),\n",
    "    ),\n",
    "    eps=measurement_noise,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Treatment #1 (baseline) - brute force workflow following [Anisotropic Metric Tutorial](../docs/examples/anisotropic_tutorial.ipynb) using single optimization step with a single initial probe point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_count = sampler.train_count\n",
    "batch_count = sampler.train_count\n",
    "num_epochs = int(train_count / batch_count)\n",
    "print(f\"train size {train_count}, batch size {batch_count}, num epochs {num_epochs}\")\n",
    "muygps_optloop = optimize_from_tensors_mini_batch(\n",
    "    muygps,\n",
    "    train_features,\n",
    "    train_responses,\n",
    "    nn_count=30,\n",
    "    batch_count=batch_count,\n",
    "    train_count=train_count,\n",
    "    num_epochs=num_epochs,\n",
    "    keep_state=False,\n",
    "    probe_previous=False,\n",
    "    batch_features=None,\n",
    "    loss_method=\"lool\",\n",
    "    obj_method=\"loo_crossval\",\n",
    "    sigma_method=\"analytic\",\n",
    "    verbose=False,\n",
    "    random_state=1,\n",
    "    init_points=5,\n",
    "    n_iter=20,\n",
    "    allow_duplicate_points=True,\n",
    ")\n",
    "print(f\"BayesianOptimization finds an optimal:\")\n",
    "print(f\"\\tlength_scale0 is {muygps_optloop.kernel.distortion_fn.length_scale['length_scale0']()}\")\n",
    "print(f\"\\tlength_scale1 is {muygps_optloop.kernel.distortion_fn.length_scale['length_scale1']()}\")\n",
    "print(f\"sigma_sq is {muygps_optloop.sigma_sq()[0]}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Treatment #2a (opt loop) - each loop interation create new optimizer instance, initialize with new objective function, and do not probe previous points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_count = sampler.train_count\n",
    "batch_count = 55\n",
    "num_epochs = int(train_count / batch_count)\n",
    "print(f\"train size {train_count}, batch size {batch_count}, num epochs {num_epochs}\")\n",
    "muygps_optloop = optimize_from_tensors_mini_batch(\n",
    "    muygps,\n",
    "    train_features,\n",
    "    train_responses,\n",
    "    nn_count=30,\n",
    "    batch_count=batch_count,\n",
    "    train_count=train_count,\n",
    "    num_epochs=num_epochs,\n",
    "    keep_state=False,\n",
    "    probe_previous=False,\n",
    "    batch_features=None,\n",
    "    loss_method=\"lool\",\n",
    "    obj_method=\"loo_crossval\",\n",
    "    sigma_method=\"analytic\",\n",
    "    verbose=False,\n",
    "    random_state=1,\n",
    "    init_points=5,\n",
    "    n_iter=20,\n",
    "    allow_duplicate_points=True,\n",
    ")\n",
    "print(f\"BayesianOptimization finds an optimal:\")\n",
    "print(f\"\\tlength_scale0 is {muygps_optloop.kernel.distortion_fn.length_scale['length_scale0']()}\")\n",
    "print(f\"\\tlength_scale1 is {muygps_optloop.kernel.distortion_fn.length_scale['length_scale1']()}\")\n",
    "print(f\"sigma_sq is {muygps_optloop.sigma_sq()[0]}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Treatment #2b (opt loop) - each loop interation create new optimizer instance, initialize with new objective function, and probe previous points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_count = 55\n",
    "train_count = sampler.train_count\n",
    "num_epochs = int(train_count / batch_count)\n",
    "print(f\"batch size {batch_count}, train size {train_count}, num epochs {num_epochs}\")\n",
    "muygps_optloop = optimize_from_tensors_mini_batch(\n",
    "    muygps,\n",
    "    train_features,\n",
    "    train_responses,\n",
    "    nn_count=30,\n",
    "    batch_count=batch_count,\n",
    "    train_count=train_count,\n",
    "    num_epochs=num_epochs,\n",
    "    keep_state=False,\n",
    "    probe_previous=True,\n",
    "    batch_features=None,\n",
    "    loss_method=\"lool\",\n",
    "    obj_method=\"loo_crossval\",\n",
    "    sigma_method=\"analytic\",\n",
    "    verbose=False,\n",
    "    random_state=1,\n",
    "    init_points=5,\n",
    "    n_iter=20,\n",
    "    allow_duplicate_points=True,\n",
    ")\n",
    "print(f\"BayesianOptimization finds an optimal:\")\n",
    "print(f\"\\tlength_scale0 is {muygps_optloop.kernel.distortion_fn.length_scale['length_scale0']()}\")\n",
    "print(f\"\\tlength_scale1 is {muygps_optloop.kernel.distortion_fn.length_scale['length_scale1']()}\")\n",
    "print(f\"sigma_sq is {muygps_optloop.sigma_sq()[0]}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Experiment #2c (opt loop) - each loop interation reuse optimizer instance, set `BayesianOptimization.TargetSpace.target_function` to new objective function, and do not probe previous points "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_count = sampler.train_count\n",
    "train_count = sampler.train_count\n",
    "num_epochs = 5\n",
    "print(f\"batch size {batch_count}, train size {train_count}, num epochs {num_epochs}\")\n",
    "muygps_optloop = optimize_from_tensors_mini_batch(\n",
    "    muygps,\n",
    "    train_features,\n",
    "    train_responses,\n",
    "    nn_count=30,\n",
    "    batch_count=batch_count,\n",
    "    train_count=train_count,\n",
    "    num_epochs=num_epochs,\n",
    "    keep_state=True,\n",
    "    probe_previous=False,\n",
    "    batch_features=None,\n",
    "    loss_method=\"lool\",\n",
    "    obj_method=\"loo_crossval\",\n",
    "    sigma_method=\"analytic\",\n",
    "    verbose=False,\n",
    "    random_state=1,\n",
    "    init_points=5,\n",
    "    n_iter=20,\n",
    "    allow_duplicate_points=True,\n",
    ")\n",
    "print(f\"BayesianOptimization finds an optimal:\")\n",
    "print(f\"\\tlength_scale0 is {muygps_optloop.kernel.distortion_fn.length_scale['length_scale0']()}\")\n",
    "print(f\"\\tlength_scale1 is {muygps_optloop.kernel.distortion_fn.length_scale['length_scale1']()}\")\n",
    "print(f\"sigma_sq is {muygps_optloop.sigma_sq()[0]}\")\n"
   ]
  }
 ],
 "metadata": {
  "@webio": {
   "lastCommId": null,
   "lastKernelId": null
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
