{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copyright 2021-2023 Lawrence Livermore National Security, LLC and other MuyGPyS\n",
    "Project Developers. See the top-level COPYRIGHT file for details.\n",
    "\n",
    "SPDX-License-Identifier: MIT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Anisotropic tutorial with optimization loop chassis\n",
    "\n",
    "This notebook walks through four experimental treatments using the optimaztion loop chassis and 2D Univariate Sampler used in the [Anisotropic Metric Tutorial](../docs/examples/anisotropic_tutorial.ipynb). The goal is to recover the response on the held-out test data by training a simple anisotropic `MuyGPS` model on the perturbed training data with `nu` smoothness hyperparameter known, while the two `distance scaling` hyperparameters are to be learned. Each iteration of the optimization loop we scale training features using learned length scale hyperparameters, update nearest neighbors lookup using sklearn, update objective function, and run bayes optimization using numpy math backend. We start by:\n",
    "1. Sampling a 2D surface from a conventional GP\n",
    "2. Create duplicate of `MuyGPyS` object used in `sampler` to be used for training and inference\n",
    "3. Execute four treatments using `optimize_from_tensors_mini_batch`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO import sys\n",
    "# for m in sys.modules.keys():\n",
    "#     if m.startswith(\"Muy\"):\n",
    "#         sys.modules.pop(m)\n",
    "# %env MUYGPYS_BACKEND=numpy\n",
    "# %env MUYGPYS_FTYPE=64\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from docs.examples.utils import UnivariateSampler2D, print_results\n",
    "\n",
    "from MuyGPyS.gp import MuyGPS\n",
    "from MuyGPyS.gp.distortion import AnisotropicDistortion, l2\n",
    "from MuyGPyS.gp.hyperparameter import ScalarHyperparameter\n",
    "from MuyGPyS.gp.kernels import Matern\n",
    "from MuyGPyS.gp.noise import HomoscedasticNoise\n",
    "from MuyGPyS.gp.tensors import make_predict_tensors\n",
    "from MuyGPyS.optimize.experimental.chassis import optimize_from_tensors_mini_batch\n",
    "\n",
    "\n",
    "def print_details(muygps_exp, train_size, batch_size, epoch_count, length_scale0, length_scale1):\n",
    "    print(f\"train size {train_size}, batch size {batch_size}, num epochs {epoch_count}\")\n",
    "    print(\"BayesianOptimization finds an optimal:\")\n",
    "    learned_sim_length_scale0 = muygps_exp.kernel.distortion_fn.length_scale['length_scale0']()\n",
    "    pe0 = abs(learned_sim_length_scale0 - length_scale0()) / length_scale0() * 100.0\n",
    "    print(f\"\\tlength_scale0 is {learned_sim_length_scale0:.4f} p.e. {pe0:2.0f}%\")\n",
    "    learned_sim_length_scale1 = muygps_exp.kernel.distortion_fn.length_scale['length_scale1']()\n",
    "    pe1 = abs(learned_sim_length_scale1 - length_scale1()) / length_scale1() * 100.0\n",
    "    print(f\"\\tlength_scale1 is {learned_sim_length_scale1:.4f} p.e. {pe1:2.0f}%\")\n",
    "    print(f\"sigma_sq is {muygps_exp.sigma_sq()[0]}\")\n",
    "\n",
    "def get_epochs(train_size=1, batch_size=1):\n",
    "    return int(train_size / batch_size)\n",
    "\n",
    "def interence(\n",
    "        muygps_optloop,\n",
    "        nbrs_lookup_final,\n",
    "        train_features_final,\n",
    "        test_features,\n",
    "        test_responses,\n",
    "        train_responses):\n",
    "    test_count, _ = test_features.shape\n",
    "    indices = np.arange(test_count)\n",
    "    test_nn_indices, _ = nbrs_lookup_final.get_nns(test_features)\n",
    "    (\n",
    "        test_crosswise_diffs,\n",
    "        test_pairwise_diffs,\n",
    "        test_nn_targets,\n",
    "    ) = make_predict_tensors(\n",
    "        indices,\n",
    "        test_nn_indices,\n",
    "        test_features,\n",
    "        train_features_final,\n",
    "        train_responses,\n",
    "    )\n",
    "    Kcross = muygps_optloop.kernel(test_crosswise_diffs)\n",
    "    K = muygps_optloop.kernel(test_pairwise_diffs)\n",
    "    predictions = muygps_optloop.posterior_mean(K, Kcross, test_nn_targets)\n",
    "    variances = muygps_optloop.posterior_variance(K, Kcross)\n",
    "    confidence_intervals = np.sqrt(variances) * 1.96\n",
    "    coverage = (\n",
    "        np.count_nonzero(\n",
    "            np.abs(test_responses - predictions) < confidence_intervals\n",
    "        ) / test_count\n",
    "    )\n",
    "    print_results(\n",
    "        \"anisotropic\",\n",
    "        test_responses,\n",
    "        predictions,\n",
    "        variances,\n",
    "        confidence_intervals,\n",
    "        coverage)\n",
    "    return predictions, confidence_intervals\n",
    "\n",
    "\n",
    "np.random.seed(0)\n",
    "\n",
    "points_per_dim = 60                             # Observations per dimension\n",
    "train_step = 13                                 # Train/test data split\n",
    "nugget_noise = HomoscedasticNoise(1e-14)        # Assume no noise in truth\n",
    "measurement_noise = HomoscedasticNoise(1e-7)    # Noise to perturb train\n",
    "sim_nu = ScalarHyperparameter(1.5)              # HP smoothness\n",
    "sim_length_scale0 = ScalarHyperparameter(0.1)   # HP distance scaling dim 0\n",
    "sim_length_scale1 = ScalarHyperparameter(0.5)   # HP distance scaling dim 1\n",
    "sampler = UnivariateSampler2D(\n",
    "    points_per_dim=points_per_dim,\n",
    "    train_step=train_step,\n",
    "    kernel=Matern(\n",
    "        nu=sim_nu,\n",
    "        metric=AnisotropicDistortion(\n",
    "            l2,\n",
    "            length_scale0=sim_length_scale0,\n",
    "            length_scale1=sim_length_scale1,\n",
    "        ),\n",
    "    ),\n",
    "    eps=nugget_noise,\n",
    "    measurement_eps=measurement_noise,\n",
    ")\n",
    "train_features, test_features = sampler.features()\n",
    "train_responses, test_responses = sampler.sample()\n",
    "# TODO sampler.plot_sample()\n",
    "\n",
    "exp_length_scale0 = ScalarHyperparameter(\"log_sample\", (0.01, 1.0))\n",
    "exp_length_scale1 = ScalarHyperparameter(\"log_sample\", (0.01, 1.0))\n",
    "muygps = MuyGPS(\n",
    "    kernel=Matern(\n",
    "        nu=sim_nu,\n",
    "        metric=AnisotropicDistortion(\n",
    "            l2,\n",
    "            length_scale0=exp_length_scale0,\n",
    "            length_scale1=exp_length_scale1,\n",
    "        ),\n",
    "    ),\n",
    "    eps=measurement_noise,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Treatment #1 (baseline) - brute force workflow following [Anisotropic Metric Tutorial](../docs/examples/anisotropic_tutorial.ipynb) using single optimization step with a single initial probe point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training\n",
    "num_epochs = get_epochs(sampler.train_count, sampler.train_count)\n",
    "(\n",
    "    muygps_optloop,\n",
    "    nbrs_lookup_final,\n",
    "    train_features_final,\n",
    ") = optimize_from_tensors_mini_batch(\n",
    "    muygps,\n",
    "    train_features,\n",
    "    train_responses,\n",
    "    nn_count=30,\n",
    "    batch_count=sampler.train_count,\n",
    "    train_count=sampler.train_count,\n",
    "    num_epochs=num_epochs,\n",
    "    keep_state=False,\n",
    "    probe_previous=False,\n",
    "    batch_features=None,\n",
    "    loss_method=\"lool\",\n",
    "    obj_method=\"loo_crossval\",\n",
    "    sigma_method=\"analytic\",\n",
    "    verbose=False,\n",
    "    random_state=1,\n",
    "    init_points=5,\n",
    "    n_iter=20,\n",
    "    allow_duplicate_points=True,\n",
    ")\n",
    "print_details(\n",
    "    muygps_optloop,\n",
    "    sampler.train_count,\n",
    "    sampler.train_count,\n",
    "    num_epochs,\n",
    "    sim_length_scale0,\n",
    "    sim_length_scale1,\n",
    ")\n",
    "\n",
    "# Inference\n",
    "predictions, confidence_intervals = interence(\n",
    "    muygps_optloop,\n",
    "    nbrs_lookup_final,\n",
    "    train_features_final,\n",
    "    test_features,\n",
    "    test_responses,\n",
    "    train_responses,\n",
    ")\n",
    "sampler.plot_predictions(predictions)\n",
    "sampler.plot_error(predictions, confidence_intervals)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Treatment #2a (opt loop) - each loop interation create new optimizer instance, initialize with new objective function, and do not probe previous points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training\n",
    "num_epochs = get_epochs(sampler.train_count, 55)\n",
    "(\n",
    "    muygps_optloop,\n",
    "    nbrs_lookup_final,\n",
    "    train_features_final, # TODO\n",
    ") = optimize_from_tensors_mini_batch(\n",
    "    muygps,\n",
    "    train_features,\n",
    "    train_responses,\n",
    "    nn_count=30,\n",
    "    batch_count=55,\n",
    "    train_count=sampler.train_count,\n",
    "    num_epochs=num_epochs,\n",
    "    keep_state=False,\n",
    "    probe_previous=False,\n",
    "    batch_features=None,\n",
    "    loss_method=\"lool\",\n",
    "    obj_method=\"loo_crossval\",\n",
    "    sigma_method=\"analytic\",\n",
    "    verbose=False,\n",
    "    random_state=1,\n",
    "    init_points=5,\n",
    "    n_iter=20,\n",
    "    allow_duplicate_points=True,\n",
    ")\n",
    "print_details(\n",
    "    muygps_optloop,\n",
    "    sampler.train_count,\n",
    "    55,\n",
    "    num_epochs,\n",
    "    sim_length_scale0,\n",
    "    sim_length_scale1,\n",
    ")\n",
    "\n",
    "# # Inference\n",
    "# predictions, confidence_intervals = interence(\n",
    "#     muygps_optloop,\n",
    "#     nbrs_lookup_final,\n",
    "#     train_features_final,\n",
    "#     test_features,\n",
    "#     test_responses,\n",
    "#     train_responses,\n",
    "# )\n",
    "# sampler.plot_predictions(predictions)\n",
    "# sampler.plot_error(predictions, confidence_intervals)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Treatment #2b (opt loop) - each loop interation create new optimizer instance, initialize with new objective function, and probe previous points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training\n",
    "num_epochs = get_epochs(sampler.train_count, 55)\n",
    "(\n",
    "    muygps_optloop,\n",
    "    nbrs_lookup_final,\n",
    "    train_features_final, # TODO\n",
    ") = optimize_from_tensors_mini_batch(\n",
    "    muygps,\n",
    "    train_features,\n",
    "    train_responses,\n",
    "    nn_count=30,\n",
    "    batch_count=55,\n",
    "    train_count=sampler.train_count,\n",
    "    num_epochs=num_epochs,\n",
    "    keep_state=False,\n",
    "    probe_previous=True,\n",
    "    batch_features=None,\n",
    "    loss_method=\"lool\",\n",
    "    obj_method=\"loo_crossval\",\n",
    "    sigma_method=\"analytic\",\n",
    "    verbose=False,\n",
    "    random_state=1,\n",
    "    init_points=5,\n",
    "    n_iter=20,\n",
    "    allow_duplicate_points=True,\n",
    ")\n",
    "print_details(\n",
    "    muygps_optloop,\n",
    "    sampler.train_count,\n",
    "    55,\n",
    "    num_epochs,\n",
    "    sim_length_scale0,\n",
    "    sim_length_scale1,\n",
    ")\n",
    "\n",
    "# # Inference\n",
    "# predictions, confidence_intervals = interence(\n",
    "#     muygps_optloop,\n",
    "#     nbrs_lookup_final,\n",
    "#     train_features_final,\n",
    "#     test_features,\n",
    "#     test_responses,\n",
    "#     train_responses,\n",
    "# )\n",
    "# sampler.plot_predictions(predictions)\n",
    "# sampler.plot_error(predictions, confidence_intervals)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Treatment #2c (opt loop) - each loop interation reuse optimizer instance, set `BayesianOptimization.TargetSpace.target_function` to new objective function, and do not probe previous points "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training\n",
    "num_epochs = 5\n",
    "(\n",
    "    muygps_optloop,\n",
    "    nbrs_lookup_final,\n",
    "    train_features_final, # TODO\n",
    ") = optimize_from_tensors_mini_batch(\n",
    "    muygps,\n",
    "    train_features,\n",
    "    train_responses,\n",
    "    nn_count=30,\n",
    "    batch_count=sampler.train_count,\n",
    "    train_count=sampler.train_count,\n",
    "    num_epochs=num_epochs,\n",
    "    keep_state=True,\n",
    "    probe_previous=False,\n",
    "    batch_features=None,\n",
    "    loss_method=\"lool\",\n",
    "    obj_method=\"loo_crossval\",\n",
    "    sigma_method=\"analytic\",\n",
    "    verbose=False,\n",
    "    random_state=1,\n",
    "    init_points=5,\n",
    "    n_iter=20,\n",
    "    allow_duplicate_points=True,\n",
    ")\n",
    "print_details(\n",
    "    muygps_optloop,\n",
    "    sampler.train_count,\n",
    "    sampler.train_count,\n",
    "    num_epochs,\n",
    "    sim_length_scale0,\n",
    "    sim_length_scale1,\n",
    ")\n",
    "\n",
    "# # Inference\n",
    "# predictions, confidence_intervals = interence(\n",
    "#     muygps_optloop,\n",
    "#     nbrs_lookup_final,\n",
    "#     train_features_final,\n",
    "#     test_features,\n",
    "#     test_responses,\n",
    "#     train_responses,\n",
    "# )\n",
    "# sampler.plot_predictions(predictions)\n",
    "# sampler.plot_error(predictions, confidence_intervals)\n"
   ]
  }
 ],
 "metadata": {
  "@webio": {
   "lastCommId": null,
   "lastKernelId": null
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
