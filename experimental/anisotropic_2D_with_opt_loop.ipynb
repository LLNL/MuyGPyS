{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copyright 2021-2023 Lawrence Livermore National Security, LLC and other MuyGPyS\n",
    "Project Developers. See the top-level COPYRIGHT file for details.\n",
    "\n",
    "SPDX-License-Identifier: MIT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Anisotropic tutorial with optimization loop chassis\n",
    "\n",
    "This notebook walks through four experimental treatments using the optimaztion loop chassis and 2D Univariate Sampler used in the [Anisotropic Metric Tutorial](../docs/examples/anisotropic_tutorial.ipynb). The goal is increase accuracy of learned hyperparameters in order to best recover the response on the held-out test data by training a simple anisotropic `MuyGPS` model on the perturbed training data with `nu` smoothness hyperparameter known, while the two `distance scaling` hyperparameters are to be learned. Each iteration of the optimization loop we scale training features using learned length scale hyperparameters, update nearest neighbors lookup using sklearn, update objective function, and run bayes optimization using numpy math backend."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import sys\n",
    "# for m in sys.modules.keys():\n",
    "#     if m.startswith(\"Muy\"):\n",
    "#         sys.modules.pop(m)\n",
    "# %env MUYGPYS_BACKEND=numpy\n",
    "# %env MUYGPYS_FTYPE=64\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from docs.examples.utils import UnivariateSampler2D\n",
    "\n",
    "from MuyGPyS.gp import MuyGPS\n",
    "from MuyGPyS.gp.distortion import AnisotropicDistortion, l2\n",
    "from MuyGPyS.gp.hyperparameter import ScalarHyperparameter\n",
    "from MuyGPyS.gp.kernels import Matern\n",
    "from MuyGPyS.gp.noise import HomoscedasticNoise\n",
    "from MuyGPyS.gp.tensors import make_predict_tensors\n",
    "from MuyGPyS.optimize.experimental.chassis import optimize_from_tensors_mini_batch\n",
    "from MuyGPyS.optimize.loss import mse_fn\n",
    "\n",
    "\n",
    "np.random.seed(0)\n",
    "\n",
    "points_per_dim = 60                             # Observations per dimension\n",
    "train_step = 13                                 # Train/test data split\n",
    "nugget_noise = HomoscedasticNoise(1e-14)        # Assume no noise in truth\n",
    "measurement_noise = HomoscedasticNoise(1e-7)    # Noise to perturb train\n",
    "sim_nu = ScalarHyperparameter(1.5)              # HP smoothness\n",
    "sim_length_scale0 = ScalarHyperparameter(0.1)   # HP distance scaling dim 0\n",
    "sim_length_scale1 = ScalarHyperparameter(0.5)   # HP distance scaling dim 1\n",
    "sampler = UnivariateSampler2D(\n",
    "    points_per_dim=points_per_dim,\n",
    "    train_step=train_step,\n",
    "    kernel=Matern(\n",
    "        nu=sim_nu,\n",
    "        metric=AnisotropicDistortion(\n",
    "            l2,\n",
    "            length_scale0=sim_length_scale0,\n",
    "            length_scale1=sim_length_scale1,\n",
    "        ),\n",
    "    ),\n",
    "    eps=nugget_noise,\n",
    "    measurement_eps=measurement_noise,\n",
    ")\n",
    "train_features, test_features = sampler.features()\n",
    "train_responses, test_responses = sampler.sample()\n",
    "# TODO sampler.plot_sample()\n",
    "\n",
    "exp_length_scale0 = ScalarHyperparameter(\"log_sample\", (0.01, 1.0))\n",
    "exp_length_scale1 = ScalarHyperparameter(\"log_sample\", (0.01, 1.0))\n",
    "muygps = MuyGPS(\n",
    "    kernel=Matern(\n",
    "        nu=sim_nu,\n",
    "        metric=AnisotropicDistortion(\n",
    "            l2,\n",
    "            length_scale0=exp_length_scale0,\n",
    "            length_scale1=exp_length_scale1,\n",
    "        ),\n",
    "    ),\n",
    "    eps=measurement_noise,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_table = [\n",
    "    [\n",
    "        \"treatment\",\n",
    "        \"time (s)\",\n",
    "        \"train size\",\n",
    "        \"batch size\", \n",
    "        \"num epochs\",\n",
    "        \"pts probed\",\n",
    "        \"l.s.0 (p.e.) \",\n",
    "        \"l.s.1 (p.e.) \",\n",
    "        \"sigma sq\",\n",
    "    ]\n",
    "]\n",
    "\n",
    "inference_table = [\n",
    "    [\n",
    "        \"treatment\",\n",
    "        \"RMSE\",\n",
    "        \"mean diag var\",\n",
    "        \"mean c.i. size \",\n",
    "        \"coverage\",\n",
    "    ]\n",
    "]\n",
    "\n",
    "inference_data = []\n",
    "\n",
    "def store_details(\n",
    "        name,\n",
    "        batch_size,\n",
    "        train_size,\n",
    "        epoch_count,\n",
    "        muygps_exp,\n",
    "        nbrs_lookup_final,\n",
    "        train_features_final,\n",
    "        exec_time,\n",
    "        probe_count\n",
    "    ):\n",
    "\n",
    "    # Training results\n",
    "    learned_sim_length_scale0 = muygps_exp.kernel.distortion_fn.length_scale['length_scale0']()\n",
    "    pe0 = abs(learned_sim_length_scale0 - sim_length_scale0()) / sim_length_scale0() * 100.0\n",
    "    learned_sim_length_scale1 = muygps_exp.kernel.distortion_fn.length_scale['length_scale1']()\n",
    "    pe1 = abs(learned_sim_length_scale1 - sim_length_scale1()) / sim_length_scale1() * 100.0\n",
    "    ret = [\n",
    "        name,\n",
    "        f\"{exec_time:.6f}\",\n",
    "        f\"{train_size}\",\n",
    "        f\"{batch_size}\",\n",
    "        f\"{epoch_count}\",\n",
    "        f\"{probe_count}\",\n",
    "        f\"{learned_sim_length_scale0:.4f} ({pe0:2.0f}%)\",\n",
    "        f\"{learned_sim_length_scale1:.4f} ({pe1:2.0f}%)\",\n",
    "        f\"{muygps_exp.sigma_sq()[0]:.4f}\",\n",
    "    ]\n",
    "    train_table.append(ret)\n",
    "\n",
    "    # Inference results\n",
    "    test_count, _ = test_features.shape\n",
    "    indices = np.arange(test_count)\n",
    "    test_nn_indices, _ = nbrs_lookup_final.get_nns(test_features)\n",
    "    (\n",
    "        test_crosswise_diffs,\n",
    "        test_pairwise_diffs,\n",
    "        test_nn_targets,\n",
    "    ) = make_predict_tensors(\n",
    "        indices,\n",
    "        test_nn_indices,\n",
    "        test_features,\n",
    "        train_features_final,\n",
    "        train_responses,\n",
    "    )\n",
    "    Kcross = muygps_exp.kernel(test_crosswise_diffs)\n",
    "    K = muygps_exp.kernel(test_pairwise_diffs)\n",
    "    predictions = muygps_exp.posterior_mean(K, Kcross, test_nn_targets)\n",
    "    variances = muygps_exp.posterior_variance(K, Kcross)\n",
    "    confidence_intervals = np.sqrt(variances) * 1.96\n",
    "    coverage = (\n",
    "        np.count_nonzero(\n",
    "            np.abs(test_responses - predictions) < confidence_intervals\n",
    "        ) / test_count\n",
    "    )\n",
    "    ret = [\n",
    "        name,\n",
    "        f\"{np.sqrt(mse_fn(predictions, test_responses)):.5f}\",\n",
    "        f\"{np.mean(variances):.5f}\",\n",
    "        f\"{np.mean(confidence_intervals * 2):.5f}\",\n",
    "        f\"{coverage:.5f}\",\n",
    "    ]    \n",
    "    inference_table.append(ret)\n",
    "    inference_data.append([predictions, confidence_intervals])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Treatment #1 (baseline) - brute force workflow following [Anisotropic Metric Tutorial](../docs/examples/anisotropic_tutorial.ipynb) using single optimization step with a single initial probe point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    muygps_optloop,\n",
    "    nbrs_lookup_final,\n",
    "    train_features_final,\n",
    "    exec_time,\n",
    "    probe_count,\n",
    ") = optimize_from_tensors_mini_batch(\n",
    "    muygps,\n",
    "    train_features,\n",
    "    train_responses,\n",
    "    nn_count=30,\n",
    "    batch_count=sampler.train_count,\n",
    "    train_count=sampler.train_count,\n",
    "    num_epochs=1,\n",
    "    keep_state=False,\n",
    "    probe_previous=False,\n",
    "    batch_features=None,\n",
    "    loss_method=\"lool\",\n",
    "    obj_method=\"loo_crossval\",\n",
    "    sigma_method=\"analytic\",\n",
    "    verbose=False,\n",
    "    random_state=1,\n",
    "    init_points=5,\n",
    "    n_iter=20,\n",
    "    allow_duplicate_points=True,\n",
    ")\n",
    "store_details(\n",
    "    \"single step\",\n",
    "    sampler.train_count,\n",
    "    sampler.train_count,\n",
    "    1,\n",
    "    muygps_optloop,\n",
    "    nbrs_lookup_final,\n",
    "    train_features_final,\n",
    "    exec_time,\n",
    "    probe_count,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Treatment #2a (opt loop) - each loop interation create new optimizer instance, initialize with new objective function, and do not probe previous points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    muygps_optloop,\n",
    "    nbrs_lookup_final,\n",
    "    train_features_final,\n",
    "    exec_time,\n",
    "    probe_count,\n",
    ") = optimize_from_tensors_mini_batch(\n",
    "    muygps,\n",
    "    train_features,\n",
    "    train_responses,\n",
    "    nn_count=30,\n",
    "    batch_count=55,\n",
    "    train_count=sampler.train_count,\n",
    "    num_epochs=(int(sampler.train_count / 55)),\n",
    "    keep_state=False,\n",
    "    probe_previous=False,\n",
    "    batch_features=None,\n",
    "    loss_method=\"lool\",\n",
    "    obj_method=\"loo_crossval\",\n",
    "    sigma_method=\"analytic\",\n",
    "    verbose=False,\n",
    "    random_state=1,\n",
    "    init_points=5,\n",
    "    n_iter=20,\n",
    "    allow_duplicate_points=True,\n",
    ")\n",
    "store_details(\n",
    "    \"no probe\",\n",
    "    55,\n",
    "    sampler.train_count,\n",
    "    (int(sampler.train_count / 55)),\n",
    "    muygps_optloop,\n",
    "    nbrs_lookup_final,\n",
    "    train_features_final,\n",
    "    exec_time,\n",
    "    probe_count,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Treatment #2b (opt loop) - each loop interation create new optimizer instance, initialize with new objective function, and probe previous points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    muygps_optloop,\n",
    "    nbrs_lookup_final,\n",
    "    train_features_final,\n",
    "    exec_time,\n",
    "    probe_count,\n",
    ") = optimize_from_tensors_mini_batch(\n",
    "    muygps,\n",
    "    train_features,\n",
    "    train_responses,\n",
    "    nn_count=30,\n",
    "    batch_count=55,\n",
    "    train_count=sampler.train_count,\n",
    "    num_epochs=(int(sampler.train_count / 55)),\n",
    "    keep_state=False,\n",
    "    probe_previous=True,\n",
    "    batch_features=None,\n",
    "    loss_method=\"lool\",\n",
    "    obj_method=\"loo_crossval\",\n",
    "    sigma_method=\"analytic\",\n",
    "    verbose=False,\n",
    "    random_state=1,\n",
    "    init_points=5,\n",
    "    n_iter=20,\n",
    "    allow_duplicate_points=True,\n",
    ")\n",
    "store_details(\n",
    "    \"probe all\",\n",
    "    55,\n",
    "    sampler.train_count,\n",
    "    (int(sampler.train_count / 55)),\n",
    "    muygps_optloop,\n",
    "    nbrs_lookup_final,\n",
    "    train_features_final,\n",
    "    exec_time,\n",
    "    probe_count,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Treatment #2c (opt loop) - each loop interation reuse optimizer instance, set `BayesianOptimization.TargetSpace.target_function` to new objective function, and do not probe previous points "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    muygps_optloop,\n",
    "    nbrs_lookup_final,\n",
    "    train_features_final,\n",
    "    exec_time,\n",
    "    probe_count,\n",
    ") = optimize_from_tensors_mini_batch(\n",
    "    muygps,\n",
    "    train_features,\n",
    "    train_responses,\n",
    "    nn_count=30,\n",
    "    batch_count=sampler.train_count,\n",
    "    train_count=sampler.train_count,\n",
    "    num_epochs=5,\n",
    "    keep_state=True,\n",
    "    probe_previous=False,\n",
    "    batch_features=None,\n",
    "    loss_method=\"lool\",\n",
    "    obj_method=\"loo_crossval\",\n",
    "    sigma_method=\"analytic\",\n",
    "    verbose=False,\n",
    "    random_state=1,\n",
    "    init_points=5,\n",
    "    n_iter=20,\n",
    "    allow_duplicate_points=True,\n",
    ")\n",
    "store_details(\n",
    "    \"reuse opt\",\n",
    "    sampler.train_count,\n",
    "    sampler.train_count,\n",
    "    5,\n",
    "    muygps_optloop,\n",
    "    nbrs_lookup_final,\n",
    "    train_features_final,\n",
    "    exec_time,\n",
    "    probe_count,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training and inference results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_len = max(len(header) for header in train_table[0])\n",
    "sep = \"-\" * max_len\n",
    "for row in train_table:\n",
    "    print(\"|\".join(header.ljust(max_len) for header in row))\n",
    "    if row == train_table[0]:\n",
    "        print(\"|\".join(sep for _ in row))\n",
    "print(\"\\n\")\n",
    "max_len = max(len(header) for header in inference_table[0])\n",
    "sep = \"-\" * max_len\n",
    "for row in inference_table:\n",
    "    print(\"|\".join(header.ljust(max_len) for header in row))\n",
    "    if row == inference_table[0]:\n",
    "        print(\"|\".join(sep for _ in row))\n",
    "\n",
    "predictions = inference_data[0][0]\n",
    "confidence_intervals = inference_data[0][1]\n",
    "fig, axes = plt.subplots(1, 4, figsize=(20, 5))\n",
    "test_im = np.zeros(sampler.data_count)\n",
    "test_im[sampler._test_mask(), None] = test_responses\n",
    "pred_im = np.zeros(sampler.data_count)\n",
    "pred_im[sampler._test_mask(), None] = predictions\n",
    "resl_im = test_im - pred_im\n",
    "resl_im[sampler._train_mask()] = -np.inf\n",
    "fig.suptitle(\"Residual\", fontsize=24)\n",
    "axes[0].set_xlabel(\"Axis 0\", fontsize=20)\n",
    "axes[0].set_ylabel(\"Axis 1\", fontsize=20)\n",
    "for index, axis in enumerate(axes):\n",
    "    im = axis.imshow(sampler._make_im(resl_im), cmap=\"coolwarm\")\n",
    "    cb = fig.colorbar(im, ax=axis, orientation='vertical')\n",
    "    axis.set_title(train_table[index + 1][0], fontsize=20)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "@webio": {
   "lastCommId": null,
   "lastKernelId": null
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
