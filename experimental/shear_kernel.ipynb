{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copyright 2023-2023 Lawrence Livermore National Security, LLC and other MuyGPyS\n",
    "Project Developers. See the top-level COPYRIGHT file for details.\n",
    "\n",
    "SPDX-License-Identifier: MIT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Shear Kernel Tutorial\n",
    "\n",
    "This notebook demonstrates how to use the specialized lensing shear kernel (hard-coded to RBF at the moment).\n",
    "\n",
    "⚠️ _Note that this is still an experimental feature._ ⚠️"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from matplotlib.colors import LogNorm\n",
    "from MuyGPyS._src.gp.tensors import _crosswise_differences, _pairwise_differences\n",
    "from MuyGPyS.gp import MuyGPS\n",
    "from MuyGPyS.gp.deformation import Isotropy, l2, F2\n",
    "from MuyGPyS.gp.hyperparameter import Parameter\n",
    "from MuyGPyS.gp.kernels.experimental import ShearKernel\n",
    "from MuyGPyS.gp.tensors import make_predict_tensors\n",
    "from MuyGPyS.neighbors import NN_Wrapper\n",
    "from MuyGPyS.gp.noise import HomoscedasticNoise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is required to import the implementation from Bob Armstrong's original repository.\n",
    "Must set `shear_kernel_dir = \"path/to/local/shear_kernel/\"` for things to run properly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib.util\n",
    "import sys\n",
    "import torch\n",
    "# introduce a variable for path/to/shear_kernel\n",
    "shear_kernel_dir = \"../../shear_kernel/\"\n",
    "spec_analytic = importlib.util.spec_from_file_location(\"analytic_kernel\", shear_kernel_dir + \"analytic_kernel.py\") \n",
    "bar = importlib.util.module_from_spec(spec_analytic)\n",
    "sys.modules[\"analytic_kernel\"] = bar\n",
    "spec_analytic.loader.exec_module(bar)\n",
    "from analytic_kernel import shear_kernel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will set a random seed here for consistency when building docs.\n",
    "In practice we would not fix a seed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we build some simple data, which is mean to represent a grid of sky coordinates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 50  # number of galaxies on a side\n",
    "xmin = 0\n",
    "xmax = 1\n",
    "ymin = 0\n",
    "ymax = 1\n",
    "\n",
    "xx = np.linspace(xmin, xmax, n)\n",
    "yy = np.linspace(ymin, ymax, n)\n",
    "\n",
    "x, y = np.meshgrid(xx, yy)\n",
    "features = np.vstack((x.flatten(), y.flatten())).T\n",
    "data_count = features.shape[0]\n",
    "diffs = _pairwise_differences(features)\n",
    "length_scale = 0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use an Isotropic distance functor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dist_fn = Isotropy(\n",
    "    metric=F2,\n",
    "    length_scale=Parameter(length_scale),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we construct a shear value kernel (partial differential components of RBF), as well as the original RBF kernel using Bob's implementation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def original_shear(X1, X2=None, length_scale=1.0):\n",
    "    if X2 is None:\n",
    "        X2 = X1\n",
    "    n1, _ = X1.shape\n",
    "    n2, _ = X2.shape\n",
    "    vals = np.zeros((3 * (n1), 3 * (n2)))\n",
    "    vals[:] = np.nan\n",
    "    for i, (ix, iy) in enumerate(X1):\n",
    "        for j, (jx, jy) in enumerate(X2):\n",
    "            tmp = shear_kernel(ix, iy, jx, jy, b=length_scale)\n",
    "            for a in range(3):\n",
    "                for b in range(3):\n",
    "                    vals[(a * n1) + i, (b * n2) + j] = tmp[a, b]\n",
    "            \n",
    "    return vals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Kin_analytic = original_shear(features, length_scale=length_scale)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we do the same using the MuyGPyS implementation. Note the increased efficiency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Kin_muygps = ShearKernel(deformation=dist_fn)(diffs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Kin_muygps` is a more generalized tensor, so we need to flatten it to a conforming shape."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Kin_flat = Kin_muygps.reshape(data_count * 3, data_count * 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Kin_analytic.shape = {Kin_analytic.shape}\")\n",
    "print(f\"Kin_muygps.shape = {Kin_muygps.shape}\")\n",
    "print(f\"Kin_flat.shape = {Kin_flat.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do the two implementations agree?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "np.allclose(Kin_analytic, Kin_flat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Kin_residual = np.abs(Kin_analytic - Kin_flat)\n",
    "print(f\"Kin residual max: {np.max(Kin_residual)}, min: {np.min(Kin_residual)}, mean : {np.mean(Kin_residual)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot results of the baseline and internal implementations. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 3, figsize=(12, 4))\n",
    "axes[0].set_title(\"original shear kernel\")\n",
    "axes[0].imshow(Kin_analytic)\n",
    "axes[1].set_title(\"MuyGPyS shear kernel\")\n",
    "axes[1].imshow(Kin_flat)\n",
    "axes[2].set_title(\"Residual\")\n",
    "im = axes[2].imshow(Kin_residual, norm=LogNorm())\n",
    "fig.colorbar(im, ax=axes[2])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we perform a similar analysis for the cross-covariance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "split = 200\n",
    "X1 = features[:split]\n",
    "X2 = features[split:]\n",
    "n1, _ = X1.shape\n",
    "n2, _ = X2.shape\n",
    "crosswise_diffs = _crosswise_differences(X1, X2)\n",
    "print(X1.shape, X2.shape, crosswise_diffs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Kcross_analytic = original_shear(X1, X2, length_scale=length_scale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Kcross_muygps = ShearKernel(deformation=dist_fn)(crosswise_diffs, adjust=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Kcross_flat = Kcross_muygps.reshape(n1 * 3, n2 * 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Kcross_analytic.shape = {Kcross_analytic.shape}\")\n",
    "print(f\"Kcross_muygps.shape = {Kcross_muygps.shape}\")\n",
    "print(f\"Kcross_flat.shape = {Kcross_flat.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.allclose(Kcross_analytic, Kcross_flat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Kcross_residual = np.abs(Kcross_analytic - Kcross_flat)\n",
    "print(f\"Kcross residual max: {np.max(Kcross_residual)}, min: {np.min(Kcross_residual)}, mean : {np.mean(Kcross_residual)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 3, figsize=(12, 4))\n",
    "axes[0].set_title(\"original shear kernel\")\n",
    "axes[0].imshow(Kcross_analytic)\n",
    "axes[1].set_title(\"MuyGPyS shear kernel\")\n",
    "axes[1].imshow(Kcross_flat)\n",
    "axes[2].set_title(\"Residual\")\n",
    "im = axes[2].imshow(Kcross_residual, norm=LogNorm())\n",
    "fig.colorbar(im, ax=axes[2])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Runtime comparison of the two implementations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if False:\n",
    "    %timeit original_shear(features)\n",
    "    %timeit ShearKernel(deformation=dist_fn)(diffs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will test the `posterior_mean` of the analytic and muygps implementations.\n",
    "First, we set up an arbitrary taget array.\n",
    "Targets should be square matrices like a grid of a swath of sky.\n",
    "Ulitimately, the target array will have shape `(625,3)`, given `n=25` above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "targets_grid_x, targets_grid_y = np.meshgrid(\n",
    "        np.linspace(1, 10, n),\n",
    "        np.linspace(1, 10, n),\n",
    "        indexing = 'ij'\n",
    "    )\n",
    "targets_grid = targets_grid_x * targets_grid_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "targets = np.vstack(\n",
    "    (targets_grid.flatten(), np.rot90(targets_grid, k=3).flatten(), np.rot90(targets_grid).flatten()),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.hstack(targets).shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normalize the data to a unit hypercube."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "targets_norm = (targets - np.min(targets)) / (np.max(targets) - np.min(targets))\n",
    "print(np.min(targets_norm), np.max(targets_norm), targets_norm.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rng = np.random.default_rng(seed=1)\n",
    "train_ratio=0.8\n",
    "interval_count = int(data_count * train_ratio)\n",
    "interval = int(data_count / interval_count)\n",
    "sfl = rng.permutation(np.arange(data_count))\n",
    "train_mask = np.zeros(data_count, dtype=bool)\n",
    "for i in range(interval_count):\n",
    "    idx = np.random.choice(sfl[i * interval : (i + 1) * interval])\n",
    "    train_mask[idx] = True\n",
    "test_mask = np.invert(train_mask)\n",
    "train_count = np.count_nonzero(train_mask)\n",
    "test_count = np.count_nonzero(test_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_targets = targets_norm[:, train_mask]\n",
    "test_targets = targets_norm[:, test_mask]\n",
    "train_features = features[train_mask, :]\n",
    "test_features = features[test_mask, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_im(vec, mask):\n",
    "    ret = np.zeros(len(mask))\n",
    "    ret[mask] = vec\n",
    "    ret[np.invert(mask)] = -np.inf\n",
    "    return ret.reshape(n, n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(3,2,figsize = (7,10))\n",
    "ax[0, 0].imshow(make_im(train_targets[0,:], train_mask))\n",
    "ax[0, 0].set_title(\"train\", fontsize = 15)\n",
    "ax[0, 0].set_ylabel(\"$\\kappa$\", fontsize = 15)\n",
    "ax[0, 1].imshow(make_im(test_targets[0,:], test_mask))\n",
    "ax[0, 1].set_title(\"test\", fontsize = 15)\n",
    "ax[1, 0].imshow(make_im(train_targets[1,:], train_mask))\n",
    "ax[1, 0].set_ylabel(\"g1\", fontsize = 15)\n",
    "ax[1, 1].imshow(make_im(test_targets[1,:], test_mask))\n",
    "ax[2, 0].imshow(make_im(train_targets[2,:], train_mask))\n",
    "ax[2, 0].set_ylabel(\"g2\", fontsize = 15)\n",
    "ax[2, 1].imshow(make_im(test_targets[2,:], test_mask))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Explicitly define the target matrices.\n",
    "Also add leading unitary dimension to `targets_muygpys` for things to work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_targets_analytic = train_targets\n",
    "test_targets_analytic = test_targets\n",
    "train_targets_muygps = train_targets[None, :, :]\n",
    "test_targets_muygps = test_targets[None, :, :]\n",
    "print(\n",
    "    train_targets_analytic.shape,\n",
    "    test_targets_analytic.shape,\n",
    "    train_targets_muygps.shape,\n",
    "    test_targets_muygps.shape,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Having defined the `K*` matrices above, compare posterior means, sans-optimization. \n",
    "This comes from (3.4) in Muyskens et al. (2021), which looks like:\n",
    "$$ \\hat{Y}(X^*|X) = K_{\\theta}(X^*,X)(K_{\\theta}(X,X)+\\epsilon)^{-1}Y(X) $$\n",
    "where $\\epsilon = \\sigma^2 I$ with $\\sigma^2$ being the noise variance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analytic: for the analytic implementation, I'll do things with the full \"flattened\" difference tensors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Kin_analytic = original_shear(train_features, train_features, length_scale=length_scale)\n",
    "Kcross_analytic = original_shear(test_features, train_features, length_scale=length_scale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(Kcross_analytic.shape, Kin_analytic.shape, train_targets_analytic.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conventional_mean(Kin, Kcross, targets, noise=1e-4):\n",
    "    response_count, train_count = targets.shape\n",
    "    test_count = int(Kcross.shape[0] / response_count)\n",
    "    return (\n",
    "        Kcross @ np.linalg.solve(\n",
    "            Kin + noise * np.identity(response_count * train_count),\n",
    "            targets.reshape(response_count * train_count),\n",
    "        )\n",
    "    ).reshape(response_count, test_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "posterior_mean_analytic = conventional_mean(\n",
    "    Kin_analytic,\n",
    "    Kcross_analytic,\n",
    "    train_targets_analytic,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MuyGPyS implementation using nearest neighbors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create MuyGPS object\n",
    "shear_model = MuyGPS(\n",
    "        kernel=ShearKernel(\n",
    "            deformation=Isotropy(\n",
    "                F2,\n",
    "                length_scale=Parameter(length_scale),\n",
    "            ),\n",
    "        ),\n",
    "        noise = HomoscedasticNoise(1e-4)\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create flat solve using MuyGPyS functions.\n",
    "This should be very close to the analytic solution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pairwise_diffs = _pairwise_differences(train_features)\n",
    "crosswise_diffs = _crosswise_differences(test_features, train_features)\n",
    "Kin_muygps = shear_model.kernel(pairwise_diffs, adjust=False)\n",
    "Kcross_muygps = shear_model.kernel(crosswise_diffs, adjust=False)\n",
    "Kin_flat = Kin_muygps.reshape(3 * train_count, 3 * train_count)\n",
    "Kcross_flat = Kcross_muygps.reshape(3 * test_count, 3 * train_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(Kin_muygps.shape, Kcross_muygps.shape, Kin_flat.shape, Kcross_flat.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\n",
    "    np.allclose(Kin_analytic, Kin_flat),\n",
    "    np.allclose(Kcross_analytic, Kcross_flat),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_im(vec, mask, ax):\n",
    "    mat = np.zeros(len(mask))\n",
    "    mat[mask] = vec\n",
    "    mat[np.invert(mask)] = -np.inf\n",
    "    im = ax.imshow(mat.reshape(n, n), norm=LogNorm())\n",
    "    fig.colorbar(im, ax=ax)\n",
    "\n",
    "def compare_predictions(truth, first, second, fname, sname, fontsize=12):\n",
    "    f_residual = np.abs(truth[:, test_mask] - first) + 1e-15\n",
    "    s_residual = np.abs(truth[:, test_mask] - second) + 1e-15\n",
    "    fs_residual = np.abs(first - second) + 1e-15\n",
    "\n",
    "    fig, ax = plt.subplots(6, 3, figsize = (10, 18))\n",
    "    \n",
    "    for axis_set in ax:\n",
    "        for axis in axis_set:\n",
    "            axis.set_xticks([])\n",
    "            axis.set_yticks([])\n",
    "\n",
    "    ax[0, 0].set_title(\"$\\kappa$\")\n",
    "    ax[0, 1].set_title(\"g1\")\n",
    "    ax[0, 2].set_title(\"g2\")\n",
    "    ax[0, 0].set_ylabel(\"Truth\", fontsize=fontsize)\n",
    "    ax[1, 0].set_ylabel(f\"{fname} Mean\", fontsize=fontsize)\n",
    "    ax[2, 0].set_ylabel(f\"|truth - {fname}|\", fontsize=fontsize)\n",
    "    ax[3, 0].set_ylabel(f\"{sname} Mean\", fontsize=fontsize)\n",
    "    ax[4, 0].set_ylabel(f\"|truth - {sname}|\", fontsize=fontsize)\n",
    "    ax[5, 0].set_ylabel(f\"|{fname} - {sname}|\", fontsize=fontsize)\n",
    "\n",
    "    # truth\n",
    "    ax[0, 0].imshow(truth[0,:].reshape(n, n))\n",
    "    ax[0, 1].imshow(truth[1,:].reshape(n, n))\n",
    "    ax[0, 2].imshow(truth[2,:].reshape(n, n))\n",
    "\n",
    "    # first model\n",
    "    ax[1, 0].imshow(make_im(first[0,:], test_mask))\n",
    "    ax[1, 1].imshow(make_im(first[1,:], test_mask))\n",
    "    ax[1, 2].imshow(make_im(first[2,:], test_mask))\n",
    "    \n",
    "    # first model residual\n",
    "    show_im(f_residual[0, :], test_mask, ax=ax[2, 0])\n",
    "    show_im(f_residual[1, :], test_mask, ax=ax[2, 1])\n",
    "    show_im(f_residual[2, :], test_mask, ax=ax[2, 2])\n",
    "\n",
    "    # second model\n",
    "    ax[3, 0].imshow(make_im(second[0,:], test_mask))\n",
    "    ax[3, 1].imshow(make_im(second[1,:], test_mask))\n",
    "    ax[3, 2].imshow(make_im(second[2,:], test_mask))\n",
    "    \n",
    "    # second model residual\n",
    "    show_im(s_residual[0, :], test_mask, ax=ax[4, 0])\n",
    "    show_im(s_residual[1, :], test_mask, ax=ax[4, 1])\n",
    "    show_im(s_residual[2, :], test_mask, ax=ax[4, 2])\n",
    "\n",
    "    # residual between the two models\n",
    "    show_im(fs_residual[0, :], test_mask, ax=ax[5, 0])\n",
    "    show_im(fs_residual[1, :], test_mask, ax=ax[5, 1])\n",
    "    show_im(fs_residual[2, :], test_mask, ax=ax[5, 2])\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "posterior_mean_flat = conventional_mean(\n",
    "    Kin_flat,\n",
    "    Kcross_flat,\n",
    "    train_targets_analytic,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compare_predictions(targets_norm, posterior_mean_flat, posterior_mean_analytic, \"flat\", \"analytic\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def muygps_mean_workflow(nn_count = 50):\n",
    "    nbrs_lookup = NN_Wrapper(train_features, nn_count, nn_method='exact', algorithm='ball_tree')\n",
    "\n",
    "    features_count = features.shape[0]\n",
    "\n",
    "    indices = np.arange(test_count)\n",
    "    test_nn_indices, _ = nbrs_lookup.get_nns(test_features)\n",
    "    \n",
    "    (\n",
    "        crosswise_diffs,\n",
    "        pairwise_diffs,\n",
    "        nn_targets,\n",
    "    ) = make_predict_tensors(\n",
    "        indices,\n",
    "        test_nn_indices,\n",
    "        test_features,\n",
    "        train_features,\n",
    "        targets_norm.swapaxes(0,1),\n",
    "    )\n",
    "\n",
    "    nn_targets= nn_targets.swapaxes(-2, -1)\n",
    "\n",
    "    Kcross = shear_model.kernel(crosswise_diffs)\n",
    "    Kin = shear_model.kernel(pairwise_diffs)\n",
    "\n",
    "    print(crosswise_diffs.shape, pairwise_diffs.shape, Kcross.shape, Kin.shape, nn_targets.shape)\n",
    "    \n",
    "    return shear_model.posterior_mean(Kin, Kcross, nn_targets).swapaxes(0,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "posterior_mean_muygps = muygps_mean_workflow(nn_count=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check numerically if things are close."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.allclose(posterior_mean_analytic, posterior_mean_muygps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "compare_predictions(targets_norm, posterior_mean_muygps, posterior_mean_analytic, \"MuyGPyS\", \"Analytic\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
